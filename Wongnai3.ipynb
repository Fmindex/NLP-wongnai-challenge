{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run setup code\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tltk\n",
    "# tltk.pos_load()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the preprocessed data\n",
    "best_processed_path = 'w_review_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'*': 11, 'other': 80, 'Z': 59, '!': 2, '๐': 165, '.': 15, 'ื': 147, 'ภ': 125, 'บ': 119, ' ': 1, 'h': 72, 'k': 75, '>': 31, '$': 5, '\\n': 0, '’': 176, 'J': 43, '7': 24, 'พ': 123, 'L': 45, 'M': 46, 'จ': 101, ':': 27, 'น': 118, 'E': 38, '0': 17, '@': 33, 'ฆ': 99, '?': 32, 'O': 48, 't': 85, 'ฑ': 110, 'j': 74, 'D': 37, 's': 84, '\"': 3, ')': 10, 'ป': 120, '๕': 170, 'โ': 153, 'เ': 151, 'I': 42, 'ฉ': 102, '๖': 171, 'H': 41, 'w': 88, '1': 18, 'B': 35, 'z': 91, 'ด': 113, '\\ufeff': 177, '๙': 174, 'ง': 100, '/': 16, 'อ': 137, 'ึ': 146, 'G': 40, 'ฯ': 139, 'U': 54, 'u': 86, '8': 25, 'ร': 128, ']': 62, '้': 160, 'K': 44, '์': 163, '6': 23, 'ใ': 154, 'ฅ': 98, 'c': 67, 'W': 56, 'b': 66, 'ฃ': 96, 'แ': 152, 'f': 70, '#': 4, 'ท': 116, \"'\": 8, 'i': 73, 'ี': 145, '&': 7, ';': 28, 'ช': 103, 'C': 36, '๔': 169, 'ฏ': 108, '๓': 168, '9': 26, 'x': 89, 'ฺ': 150, 'X': 57, 'ย': 127, 'ษ': 133, '๘': 173, '+': 12, 'r': 83, 'ฝ': 122, '5': 22, 'ๆ': 157, 'a': 65, '3': 20, '^': 63, 'ำ': 143, 'ิ': 144, 'ส': 134, '๋': 162, 'ข': 95, 'ๅ': 156, '%': 6, '‘': 175, 'ฮ': 138, ',': 13, 'n': 78, 'ฟ': 124, 'ซ': 104, '่': 159, '-': 14, 'Q': 50, 'S': 52, 'N': 47, 'ต': 114, '<': 29, '(': 9, 'ก': 94, '็': 158, 'ว': 131, 'ศ': 132, 'V': 55, 'ฌ': 105, '4': 21, 'Y': 58, 'A': 34, '=': 30, 'ฒ': 111, 'ถ': 115, 'ญ': 106, 'ฐ': 109, 'e': 69, 'า': 142, 'ม': 126, 'ณ': 112, 'q': 82, '}': 92, 'ู': 149, 'm': 77, 'T': 53, '\\\\': 61, 'R': 51, '~': 93, 'ผ': 121, '๊': 161, 'ล': 130, '๗': 172, 'v': 87, 'ฬ': 136, 'F': 39, 'l': 76, 'y': 90, 'ะ': 140, 'P': 49, 'd': 68, 'ั': 141, 'ฤ': 129, '[': 60, 'ฎ': 107, '๑': 166, 'ไ': 155, 'ุ': 148, 'ํ': 164, '๒': 167, 'p': 81, '_': 64, 'g': 71, 'ห': 135, 'o': 79, 'ธ': 117, '2': 19, 'ค': 97}\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "# Create a character map\n",
    "CHARS = [\n",
    "  '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
    "  ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "  '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n",
    "  'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "  'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_',\n",
    "  'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "  'n', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "  'z', '}', '~', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช',\n",
    "  'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท',\n",
    "  'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ',\n",
    "  'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า',\n",
    "  'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ',\n",
    "  'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๐', '๑', '๒', '๓',\n",
    "  '๔', '๕', '๖', '๗', '๘', '๙', '‘', '’', '\\ufeff'\n",
    "]\n",
    "CHARS_MAP = {v: k for k, v in enumerate(CHARS)}\n",
    "print(CHARS_MAP)\n",
    "print(len(CHARS_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding,Dense, Conv1D, Flatten, TimeDistributed, Dropout\n",
    "from keras.layers import Input, GRU, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "# def get_my_best_model2():\n",
    "#     input1 = Input(shape=(21,))\n",
    "#     x = Embedding(178,8)(input1)\n",
    "#     x = Conv1D(100,5,strides=1,activation='relu',padding=\"same\")(x)\n",
    "#     x = TimeDistributed(Dense(5))(x)ฅ\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(0.05)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(0.05)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(0.05)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     out = Dense(1, activation='sigmoid')(x)\n",
    "#     model = Model(inputs=input1, outputs=out)\n",
    "#     model.compile(optimizer=Adam(),\n",
    "#                  loss='binary_crossentropy',\n",
    "#                  metrics=['acc'])          \n",
    "#     return model\n",
    "\n",
    "def get_my_best_model():\n",
    "    input1 = Input(shape=(21,))\n",
    "    x = Embedding(178,8)(input1)\n",
    "    x = Conv1D(100,5,strides=1,activation='relu',padding=\"same\")(x)\n",
    "    x = TimeDistributed(Dense(5))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])          \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 21, 8)             1424      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 21, 100)           4100      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 21, 5)             505       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 105)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 36,930\n",
      "Trainable params: 36,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_path_my_best_model2='model_best.h5'\n",
    "my_best_model2 = get_my_best_model()\n",
    "my_best_model2.load_weights(weight_path_my_best_model2)\n",
    "#my_best_model2.make_predict_function()\n",
    "my_best_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(best_processed_path, sep=';', header=None)\n",
    "df2 = pd.read_csv(\"test_file.csv\", sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1            ร้านนี้จะอยู่เส้นสันกำแพง-แม่ออน เลยแยกบ่...\n",
       "2       สั่งไป2 เมนู คือมัชฉะลาเต้ร้อน กับ ไอศครีมชาเข...\n",
       "3       ครัววงเดือน  \\n\\nหิวดึกๆ ตระเวนหาร้านทาน มาเจอ...\n",
       "4            จะว่าเป็นเจ้าประจำก็คงไม่ผิด แต่ก็ไม่กล้า...\n",
       "5       ถ้าคิดถึงสลัดผมคิดถึงร้านนี้เป็นร้านแรกๆเลยครั...\n",
       "6       กระบี่ก็ต้องไม่พลาด ร้านนี้ค่ะ ร้านปูดำ ส่วนอา...\n",
       "7       ร้านดัง  ของหวานอร่อยที่สุดก็คงต้องยกให้  afte...\n",
       "8       อาหารหลากหลายไทย จีน ฝรั่ง ชาบูก็มา ของหวานมีฮ...\n",
       "9       เป็นร้านอาหารเพื่อสุขภาพที่รสชาติดี ทานแล้วไม่...\n",
       "10      ดีใจที่จุดพักรถมอร์เตอร์เวย์ขาเข้า มีร้านอาหาร...\n",
       "11      ร้านชาบูเล็กๆ ราคาเบาๆ แต่คุณภาพคับแก้ว shabuy...\n",
       "12      ร้านนี้เป็นร้านกระทะร้อนโด่งดังในย่านเยาวราช ม...\n",
       "13        》 มาธุระแถวพืชสวนโลก เกินเวลาทานมื้อเที่ยง เ...\n",
       "14      เป็นร้านกาแฟอยู่ในร้านอาหารเสน่ห์ดอยหลวง \\nร้า...\n",
       "15      เป็นร้านข้าวซอยที่อยู่แถวสี่แยกไปอำเภอปาย ร้าน...\n",
       "16      หาร้านทานตอนกลางวันวันเสาร์แบบด่วนๆ จองร้านนี้...\n",
       "17      ร้านปิ้งย่างบุฟเฟห์เกาหลี โดยคนเกาหลี กับร้าน ...\n",
       "18      ร้านนี้เป็นร้านเล็กๆที่บรรยากาศดีเห็นแล้วอยากม...\n",
       "19      ร้าน potato corner สาขาเซ็นทรัลลาดพร้าว ตั้งอย...\n",
       "20      เจ้าถิ่นอุดรพามา บอกต้องกินนะ จัดไปอย่างเต็ม\\n...\n",
       "21      ครั้งนี้ ตั้งใจจะมาทานกระดูกอ่อนต้มยำหม้อไฟค่ะ...\n",
       "22      ร้านตั้งอยู่ฝั่งตรงข้ามกับคลองทวีวัฒนา สามารถจ...\n",
       "23      ไหนๆข้ามฝั่งธนมา เลยขอลองร้าน Shibuya Shabu ซะ...\n",
       "24      ร้านนี้เป็นร้านประจำของผมเลยก็ว่าได้ เหมาะแก่ก...\n",
       "25      ไปเที่ยงคนตรึม ร้านริมถนนบ้านๆ เตี๋ยวหมู/ไก่ยอ...\n",
       "26      เป็นร้านก๋วยเตี๋ยวแคระที่เปิดมานาน อยู่ในย่านร...\n",
       "27      ผ่านประจำไม่เคยได้แวะทานสักที เพิ่งจะมีโอกาสแว...\n",
       "28           ร้านกาแฟริมท้องนา ที่เราเองต้องยอมรับว่าม...\n",
       "29      วันตรุษจีนมาทานข้าวกับอากงอาม่าที่ร้านนี้ครับ ...\n",
       "30      เดินผ่านร้าน กาลนาน ณ วันวาน ที่ เมกะบางนา แล้...\n",
       "                              ...                        \n",
       "6174    คิดถึงป๊อบคอนที่โด่งดังขึ้นชื่อ อร่อยไม่ต้องไป...\n",
       "6175    ร้าน Dancing Crab เป็นอีกร้านเด็ดในศูนย์อาหาร ...\n",
       "6176    มาถึงเชียงใหม่ตอนสาย ทำงานปอบๆ เสร็จละค่ะ หิวจ...\n",
       "6177    ลองชาบูนางในมาก็หลายสาขา แต่ชอบสาขานี้มากที่สุ...\n",
       "6178    เพื่อนแนะนำมา ว่าอร่อยมาก แต่สงสัยจะไม่ถูกปากเ...\n",
       "6179    ร้านนี้น้องปอบเคยมาจิบกาแฟเมื่อหลายปีก่อน แม้จ...\n",
       "6180    ร้านกาแฟที่ไม่ได้มีแต่กาแฟ!!\\n\\nตั้งอยู่บนถนนท...\n",
       "6181    ได้รับเชิญจากทางร้านและวงใน ไปชิมอาหารที่ร้าน ...\n",
       "6182    วัดโบสถ์ ไม่มีใครไม่รู้จัก ส้มตำป้าเเมว\\nร้านน...\n",
       "6183      ร้านครัวต้นเตย บรรยากาศดีค่ะ มีโซนด้านนอกด้า...\n",
       "6184    ก่อนอื่นต้องออกตัวเลยว่าเป็นคนไม่ชอบกินผัก เพร...\n",
       "6185    บรรยากาศดี ปลอดโปร่ง ดูกว้างขวาง\\nชอบเพดานหลัง...\n",
       "6186    ชื่อร้าน เตี๋ยวทีบาร์ แต่เมนูที่มีให้เลือกลองช...\n",
       "6187    ครั้งนี้ได้มาร่วมกิจกรรม Wongnai Tasting x Can...\n",
       "6188    sushi express ชื่อก้อบอกแล้วว่า ซูชิด่วนๆ \\nเส...\n",
       "6189    ร้านเล็กๆสีเหลือง หาง่าย มีที่จอดรถ\\n\\n\\n-มีที...\n",
       "6190    ใครชื่นชอบเห็ดร้านนี้ถือว่า เด็ด สุดๆ ร้านโปร่...\n",
       "6191    พึ่งมีโอกาสแวะมาทานร้านนี้ที่สาขาเมืองไทย จริง...\n",
       "6192    แวะมาลองกินขนมกัน มีพวกเครป ไอติม วาฟเฟิล และข...\n",
       "6193    ไม่ได้มากินนานมาก น่าจะ 7-8 ปีได้ รสชาติยังดีอ...\n",
       "6194    ต้มเลือดหมูนายดอน สาขา2 อยู่ใกล้ๆ 5แยกค่ะ เยื้...\n",
       "6195    บรรยายกาศร้านสไตล์ชิวๆน่านั่ง ตอนนี้ร้านใหม่ย้...\n",
       "6196    กินร้านนี้ตั้งแต่ตอนยังเป็นร้านเล็กๆ จนตอนนี้ข...\n",
       "6197    น้ำแข็งใสแอบผิดหวังนิดหน่อย เป็นเกร็ดน้ำแข็งมา...\n",
       "6198    วนหาที่จอดรถกับซักเล็กน้อยแต่คุ้มค่านะค่ะ บิงซ...\n",
       "6199    ร้านโรตีสายไหมพญาวัง อยู่ถนนรัตนโกสินทร์ หลังโ...\n",
       "6200    ข้าวผัดคอหมูย่าง ข้าวผัดมากลิ่นหอม คอหมูย่างอร...\n",
       "6201    ร้านอาหารมีหลายโซน แนะนำให้เดินดูก่อนค่อยเลือก...\n",
       "6202         ขนมปังร้านในเครือยามาซากิ จริงๆร้านนี้เปิ...\n",
       "6203    ร้านอาหารใหญ่มากกกกกกก \\nเลี้ยวเข้ามาเจอห้องน้...\n",
       "Name: 1, Length: 6203, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = df2[1][1:]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_n_gram_df(df, n_pad):\n",
    "  \"\"\"\n",
    "  Given an input dataframe, create a feature dataframe of shifted characters\n",
    "  Input:\n",
    "  df: timeseries of size (N)\n",
    "  n_pad: the number of context. For a given character at position [idx],\n",
    "    character at position [idx-n_pad/2 : idx+n_pad/2] will be used \n",
    "    as features for that character.\n",
    "  \n",
    "  Output:\n",
    "  dataframe of size (N * n_pad) which each row contains the character, \n",
    "    n_pad_2 characters to the left, and n_pad_2 characters to the right\n",
    "    of that character.\n",
    "  \"\"\"\n",
    "  n_pad_2 = int((n_pad - 1)/2)\n",
    "  for i in range(n_pad_2):\n",
    "      df['char-{}'.format(i+1)] = df[0].shift(i + 1)\n",
    "      df['char{}'.format(i+1)] = df[0].shift(-i - 1)\n",
    "  return df[n_pad_2: -n_pad_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "อาหารที่นี่เป็นอาหารจีนแคะที่หากินยากในบ้านเรา ตัวร้านตั้งอยู่ที่ถนนพุทธมณฑลสาย 3 ไปตาม ถ.ปิ่นเกล้า-นครชัยศรี เมื่อถึงพุทธมณฑลสาย 3 ก็เลี้ยวเข้าไปประมาณ 500 เมตร ร้านอยู่ทางซ้ายมือค่ะ มีคนบอกมาว่าความพิเศษของร้านนี้คือกุ๊กเก่าและเป็นกุ๊กรุ่นสุดท้ายจาก \"ฮก ลก ซิ่ว” ภัตตาคารจีนชื่อดังย่านราชประสงค์ ที่เลิกกิจการไปแล้ว ต้องคนที่อายุเลข 5 ขึ้นไปจึงจะเคยกิน ฮก ลก ซิ่ว  จานเด็ดที่มีขายที่นี่แห่งเดียวในเมืองไทยคือ ปลาเต๋าเต้ย 2 ฤดู เป็นสูตรจากมาเลเซีย นอกนั้นก็มี ผัดผักน้ำมันหอย ไก่เบตง เคาหยก ปูทะเลซุปน้ำใสหม้อไฟ เต้าหู้แคระยัดไส้หม้อดิน และ ลูกชิ้นแคระ \n",
      "อาหารที่เราแนะนำคือไก่เบตง (คล้ายๆไก่แช่เหล้า) เสริฟพร้อมกับหอมเจียว และน้ำจิ้มน้ำพริกเผาสูตรเด็ดของทางร้าน \n",
      "เมนูข้าวผัดหนำเลียบก็อร่อยค่ะ ชอบมากๆ\n"
     ]
    }
   ],
   "source": [
    "word_test = [x for x in df[0][1]]\n",
    "print(''.join(word_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CHARS_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-faca8ebe6172>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#print(word_test_df2[0][:21])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;31m# arg is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66645)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-faca8ebe6172>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#print(word_test_df2[0][:21])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'CHARS_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "word_test_df2 = pd.DataFrame(word_test)\n",
    "#print(word_test_df2)\n",
    "\n",
    "n_pad = 21\n",
    "n_pad_2 = int((n_pad - 1)/2)\n",
    "pad = [{0: ' '}]\n",
    "df_pad = pd.DataFrame(pad * n_pad_2)\n",
    "#print(df_pad)\n",
    "\n",
    "word_test_df2 = pd.concat((df_pad, word_test_df2, df_pad))\n",
    "#print(word_test_df2[0][:21])\n",
    "word_test_df2[0] = word_test_df2[0].map(lambda x: CHARS_MAP.get(x, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_context = create_n_gram_df(word_test_df2, n_pad=n_pad)\n",
    "\n",
    "char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
    "             ['char-' + str(i + 1) for i in range(n_pad_2)] + [0]\n",
    "\n",
    "# convert pandas dataframe to numpy array to feed to the model\n",
    "x_char = df_with_context[char_row].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ก'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e9ddd45dbc2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_best_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprob_to_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob_to_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1713\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1267\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ก'"
     ]
    }
   ],
   "source": [
    "y_pred = my_best_model2.predict(x_char)\n",
    "\n",
    "prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "y_pred = np.apply_along_axis(prob_to_class,1,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ede0294bc0a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mword_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print(len(word_test))\n",
    "word_token = []\n",
    "word_tmp = ''\n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i] == 1):\n",
    "        word_token.append(word_tmp)\n",
    "        word_tmp = ''\n",
    "    word_tmp += word_test[i]\n",
    "else:\n",
    "    word_token.append(word_tmp)\n",
    "word_token = word_token[1:]\n",
    "print(word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cutKumKrub(string):\n",
    "    word_test = [x for x in string]\n",
    "    word_test_df2 = pd.DataFrame(word_test)\n",
    "\n",
    "    n_pad = 21\n",
    "    n_pad_2 = int((n_pad - 1)/2)\n",
    "    pad = [{0: ' '}]\n",
    "    df_pad = pd.DataFrame(pad * n_pad_2)\n",
    "\n",
    "    word_test_df2 = pd.concat((df_pad, word_test_df2, df_pad))\n",
    "    word_test_df2[0] = word_test_df2[0].map(lambda x: CHARS_MAP.get(x, 80))\n",
    "    \n",
    "    df_with_context = create_n_gram_df(word_test_df2, n_pad=n_pad)\n",
    "\n",
    "    char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
    "                 ['char-' + str(i + 1) for i in range(n_pad_2)] + [0]\n",
    "\n",
    "    # convert pandas dataframe to numpy array to feed to the model\n",
    "    x_char = df_with_context[char_row].as_matrix()\n",
    "    \n",
    "    y_pred = my_best_model2.predict(x_char)\n",
    "\n",
    "    prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "    y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
    "    \n",
    "    word_token = []\n",
    "    word_tmp = ''\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i] == 1):\n",
    "            word_token.append(word_tmp)\n",
    "            word_tmp = ''\n",
    "        word_tmp += word_test[i]\n",
    "    else:\n",
    "        word_token.append(word_tmp)\n",
    "    word_token = word_token[1:]\n",
    "    return word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeLabel(review, rating):\n",
    "    noSpace = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, cutKumKrub(review)))\n",
    "    cleaned = list(filter(lambda x: len(x.replace(\" \\n\", \"\")) > 0 and len(x.replace(\")\", \"\")) > 0, noSpace)) \n",
    "    for i in range(len(cleaned)):\n",
    "        cleaned[i] = cleaned[i].replace(\"\\n\", \"\")\n",
    "        cleaned[i] = cleaned[i].replace(\"(\", \"\")\n",
    "        cleaned[i] = cleaned[i].replace(\")\", \"\")\n",
    "    finalWord = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, cleaned))\n",
    "    label = [int(rating)] * len(cleaned)\n",
    "    training_data = list(zip(cleaned, label))\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CHARS_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4fd7c6537aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmergeLabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-986368468bf9>\u001b[0m in \u001b[0;36mmergeLabel\u001b[1;34m(review, rating)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmergeLabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mnoSpace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutKumKrub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\")\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoSpace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-6b0c1ff35149>\u001b[0m in \u001b[0;36mcutKumKrub\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdf_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_n_gram_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;31m# arg is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66645)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-6b0c1ff35149>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdf_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_n_gram_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CHARS_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "mergeLabel(df[0][1], df[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ร้านอาหารใหญ่มากกกกกกก \\nเลี้ยวเข้ามาเจอห้องน้...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>อาหารที่นี่เป็นอาหารจีนแคะที่หากินยากในบ้านเรา...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ปอเปี๊ยะสด ทุกวันนี้รู้สึกว่าหากินยาก (ร้านที่...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>รัานคัพเค้กในเมืองไทยมีไม่มาก หลายๆคนอาจจะสงสั...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>อร่อย!!! เดินผ่านDigital gatewayทุกวัน ไม่ยักร...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ร้านข้าวต้มกระดูกหมู ปากซอยพัฒนาการ 57 เป็นอีก...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>วันนี้ได้มีโอกาสไปนั่งซดกาแฟที่ร้านวาวี แถวๆอา...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>สารภาพว่าไม่เคยคิดจะไปต่อคิวซื้อมากินเองครับ บ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>เมื่อวันก่อนไปเดินเล่น แบบชิวๆๆ ที่สยามสแควร์แ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>วันก่อนไปเดินสยาม หลังจากห่างหายไป ประมาณ 6 เด...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>พามาลองอะไรใกล้ๆ บ้านบ้างครับ .. ร้าน \"วัวหัวเ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>เพ่ิงกลับมาจากไต้หวันก็ไปลองร้านนี้ทันที ชานมไ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>เคยไปทานที่ Villa มา คนเยอะมากกกกก รอคิวนานประ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>เหมือนกับรีวิวก่อนๆค่ะ เมนูที่ห้ามพลาดก้อคือ S...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"ประจักษ์เป็ดย่าง\" \\n\\nไม่ใช่ร้านของพันตรีประจ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ร้านนี้ถ้าวิวให้หกดาวได้ผมให้วิวหกดาว..\\n\\nร้า...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ก้ำกึ่งระหว่าง 4 ดาวกับ 5 ดาว แต่ถ้าเทียบกับร้...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>เป็นร้านที่มีเครื่องดื่มให้เลือกมากมาย และรสชา...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ร้านคุณภาพอีกร้านนึงครับ ปกติกินที่สาขาสยามรู้...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ก๋วยเตี๋ยวลูกชิ้นปลาย่านคลองเตยร้านนี้เปิดมาเป...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ร้านอาหารญี่ปุ่นร้านนี้ ใจจริงไม่อยากแนะนำเลยค...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ร้านชีสเค้กต้นตำรับจากนิวยอร์ก\\nร้านอยู่ที่CDC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ระหว่างทางไปเขาค้อ ผมได้คำแนะนำจากเด็กปั๊มให้ม...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ใครที่เดินทางไปเที่ยวชะอำหรือหัวหิน ก็ต้องหาอา...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>เดือนแรกที่เค้าต่อคิวกัน 2 - 3 ชั่วโมง เราก็ว่...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>หลังจากที่โดนยั่วโดยหลายๆ เว็บ หลายๆ ทวีต วันน...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>เข้าวังไปจิบกาแฟกันนะครับ บอกได้เลยว่า มาร้านน...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>กินจนติดมาก เป็นร้านที่กินแล้ว \"สนุกลิ้น\" มากจ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>เพิ่งจะเปิดได้ไม่กี่ปีแต่ต้องยอมรับว่าเค้าประส...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ร้านไอส์เบิร์กอยู่ที่นครปฐม ทั้งร้านขายไอศกรีม...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39970</th>\n",
       "      <td>เป็นร้านเล็กๆ ของโรงแรมคอนราดตั้งอยุ่ชั้น 2 ขอ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39971</th>\n",
       "      <td>รู้สึกว้าววกับเมนูนี้มากเลยยค่าปป ผมรู้สึกมันเ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39972</th>\n",
       "      <td>???? Hongbao Dimsum House~ rest area ทางด่วนปร...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39973</th>\n",
       "      <td>พนักงานบริการดี อาหารคุ้มกับราคาค่ะ ร้านใหญ่ ภ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39974</th>\n",
       "      <td>ร้านหมูกระทะที่มีทุกอย่างครบคลุมไว้ละปิ้งย่าง ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39975</th>\n",
       "      <td>ร้านเทมปุระ ที่ได้รับการแนะนำจาก Tripadvisor เ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39976</th>\n",
       "      <td>กินเส้น กรือกินเนื้อ หรือกินหยัง เลือกเอา เลือ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39977</th>\n",
       "      <td>กาแฟมิตรสัมพันธ์ – สิ่งที่เราชอบเกี่ยวกับร้านก...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39978</th>\n",
       "      <td>ชื่อร้านก็บอกแล้วว่าสารพัดเส้น ก็ต้องจัดเส้น เ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39979</th>\n",
       "      <td>ร้านอาหารที่อยู่โซนหน้าห้างเซ็นทรัลอีสต์วิลล์ ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39980</th>\n",
       "      <td>มื้อกลางวันวันนี้ เราแวะมาทานที่  Jewelry Trad...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>ขนมจีนน้ำยาปู หาร้านทำอร่อยยากอยู่นะ เคยกินบาง...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39982</th>\n",
       "      <td>บางครั้งหิวตอนดึกๆ หรือนัดเพื่อนฝูงตอนกลางคืน ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39983</th>\n",
       "      <td>Osha Cafe' ตั้งอยู่บริเวณโกดัง10 ของโครงการAsi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39984</th>\n",
       "      <td>ฝากท้องฝากไส้กันไป ออกมานอกพื้นที่ ทานร้านริมท...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>ร้านกาแฟ ในเชียงใหม่ มีมากมายหลายร้าน ยิ่งกว่า...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>โดนัทเจ้าดังที่สร้างตำนานคิวย๊าวยาวววว จริงๆกิ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>เวลามาสีลมแล้วอย่กนั่งชิล หรือทำงานไปด้วยก็จะเ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>ร้านเจ้าประจำเวลานึกถึงกาแฟอีกร้าน แต่ถ้าเป็นช...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>ร้านข้าวมันไก่ในซอยวัดหนองขาม มาแวะซื้อใส่กล่อ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39990</th>\n",
       "      <td>ร้านอยู่กลางเมกะบางนา ตรงประชาสัมพันธ์ ใต้บันไ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39991</th>\n",
       "      <td>เป็นร้านนั่งชิวขึ้นชื่อของโซนนี้ที่ต้องมาลองให...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39992</th>\n",
       "      <td>ร้านที่ชื่อแปลก ตกแต่งสไตล์loft ได้อย่างลงตัว ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39993</th>\n",
       "      <td>นั่งกิน Bar B Q กันอยู่ มองไปทาง food court เห...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>\"อร่อย ขนมจีบ ซาลาเปา\" ขนมจีบลูกใหญ่ กับซาลาเป...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>รู้จักร้านนี้จากวงใน ร้านอยู่ในอาคารพาณิชย์ตรง...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>ร้านซูชิอาหารญี่ปุ่น อยู่ตรงสะพานลอย เกษตรประต...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>\"Cantina Wine Bar &amp; Italian Kitchen\" ร้านเล็กๆ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>ร้านเค้กน่ารักๆ ตรงชั้นล่างของห้างเซ็นทรัลลาดพ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>วันนี้มากินกันไกลถึงแม่สอดจังหวัดตากติดกับชายแ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  1\n",
       "0      ร้านอาหารใหญ่มากกกกกกก \\nเลี้ยวเข้ามาเจอห้องน้...  3\n",
       "1      อาหารที่นี่เป็นอาหารจีนแคะที่หากินยากในบ้านเรา...  4\n",
       "2      ปอเปี๊ยะสด ทุกวันนี้รู้สึกว่าหากินยาก (ร้านที่...  3\n",
       "3      รัานคัพเค้กในเมืองไทยมีไม่มาก หลายๆคนอาจจะสงสั...  5\n",
       "4      อร่อย!!! เดินผ่านDigital gatewayทุกวัน ไม่ยักร...  5\n",
       "5      ร้านข้าวต้มกระดูกหมู ปากซอยพัฒนาการ 57 เป็นอีก...  4\n",
       "6      วันนี้ได้มีโอกาสไปนั่งซดกาแฟที่ร้านวาวี แถวๆอา...  4\n",
       "7      สารภาพว่าไม่เคยคิดจะไปต่อคิวซื้อมากินเองครับ บ...  3\n",
       "8      เมื่อวันก่อนไปเดินเล่น แบบชิวๆๆ ที่สยามสแควร์แ...  5\n",
       "9      วันก่อนไปเดินสยาม หลังจากห่างหายไป ประมาณ 6 เด...  5\n",
       "10     พามาลองอะไรใกล้ๆ บ้านบ้างครับ .. ร้าน \"วัวหัวเ...  4\n",
       "11     เพ่ิงกลับมาจากไต้หวันก็ไปลองร้านนี้ทันที ชานมไ...  4\n",
       "12     เคยไปทานที่ Villa มา คนเยอะมากกกกก รอคิวนานประ...  4\n",
       "13     เหมือนกับรีวิวก่อนๆค่ะ เมนูที่ห้ามพลาดก้อคือ S...  4\n",
       "14     \"ประจักษ์เป็ดย่าง\" \\n\\nไม่ใช่ร้านของพันตรีประจ...  4\n",
       "15     ร้านนี้ถ้าวิวให้หกดาวได้ผมให้วิวหกดาว..\\n\\nร้า...  4\n",
       "16     ก้ำกึ่งระหว่าง 4 ดาวกับ 5 ดาว แต่ถ้าเทียบกับร้...  5\n",
       "17     เป็นร้านที่มีเครื่องดื่มให้เลือกมากมาย และรสชา...  5\n",
       "18     ร้านคุณภาพอีกร้านนึงครับ ปกติกินที่สาขาสยามรู้...  4\n",
       "19     ก๋วยเตี๋ยวลูกชิ้นปลาย่านคลองเตยร้านนี้เปิดมาเป...  5\n",
       "20     ร้านอาหารญี่ปุ่นร้านนี้ ใจจริงไม่อยากแนะนำเลยค...  5\n",
       "21     ร้านชีสเค้กต้นตำรับจากนิวยอร์ก\\nร้านอยู่ที่CDC...  4\n",
       "22     ระหว่างทางไปเขาค้อ ผมได้คำแนะนำจากเด็กปั๊มให้ม...  3\n",
       "23     ใครที่เดินทางไปเที่ยวชะอำหรือหัวหิน ก็ต้องหาอา...  4\n",
       "24     เดือนแรกที่เค้าต่อคิวกัน 2 - 3 ชั่วโมง เราก็ว่...  5\n",
       "25     หลังจากที่โดนยั่วโดยหลายๆ เว็บ หลายๆ ทวีต วันน...  5\n",
       "26     เข้าวังไปจิบกาแฟกันนะครับ บอกได้เลยว่า มาร้านน...  4\n",
       "27     กินจนติดมาก เป็นร้านที่กินแล้ว \"สนุกลิ้น\" มากจ...  4\n",
       "28     เพิ่งจะเปิดได้ไม่กี่ปีแต่ต้องยอมรับว่าเค้าประส...  5\n",
       "29     ร้านไอส์เบิร์กอยู่ที่นครปฐม ทั้งร้านขายไอศกรีม...  4\n",
       "...                                                  ... ..\n",
       "39970  เป็นร้านเล็กๆ ของโรงแรมคอนราดตั้งอยุ่ชั้น 2 ขอ...  4\n",
       "39971  รู้สึกว้าววกับเมนูนี้มากเลยยค่าปป ผมรู้สึกมันเ...  5\n",
       "39972  ???? Hongbao Dimsum House~ rest area ทางด่วนปร...  4\n",
       "39973  พนักงานบริการดี อาหารคุ้มกับราคาค่ะ ร้านใหญ่ ภ...  4\n",
       "39974  ร้านหมูกระทะที่มีทุกอย่างครบคลุมไว้ละปิ้งย่าง ...  3\n",
       "39975  ร้านเทมปุระ ที่ได้รับการแนะนำจาก Tripadvisor เ...  4\n",
       "39976  กินเส้น กรือกินเนื้อ หรือกินหยัง เลือกเอา เลือ...  4\n",
       "39977  กาแฟมิตรสัมพันธ์ – สิ่งที่เราชอบเกี่ยวกับร้านก...  4\n",
       "39978  ชื่อร้านก็บอกแล้วว่าสารพัดเส้น ก็ต้องจัดเส้น เ...  3\n",
       "39979  ร้านอาหารที่อยู่โซนหน้าห้างเซ็นทรัลอีสต์วิลล์ ...  4\n",
       "39980  มื้อกลางวันวันนี้ เราแวะมาทานที่  Jewelry Trad...  3\n",
       "39981  ขนมจีนน้ำยาปู หาร้านทำอร่อยยากอยู่นะ เคยกินบาง...  4\n",
       "39982  บางครั้งหิวตอนดึกๆ หรือนัดเพื่อนฝูงตอนกลางคืน ...  4\n",
       "39983  Osha Cafe' ตั้งอยู่บริเวณโกดัง10 ของโครงการAsi...  4\n",
       "39984  ฝากท้องฝากไส้กันไป ออกมานอกพื้นที่ ทานร้านริมท...  4\n",
       "39985  ร้านกาแฟ ในเชียงใหม่ มีมากมายหลายร้าน ยิ่งกว่า...  4\n",
       "39986  โดนัทเจ้าดังที่สร้างตำนานคิวย๊าวยาวววว จริงๆกิ...  4\n",
       "39987  เวลามาสีลมแล้วอย่กนั่งชิล หรือทำงานไปด้วยก็จะเ...  3\n",
       "39988  ร้านเจ้าประจำเวลานึกถึงกาแฟอีกร้าน แต่ถ้าเป็นช...  4\n",
       "39989  ร้านข้าวมันไก่ในซอยวัดหนองขาม มาแวะซื้อใส่กล่อ...  3\n",
       "39990  ร้านอยู่กลางเมกะบางนา ตรงประชาสัมพันธ์ ใต้บันไ...  3\n",
       "39991  เป็นร้านนั่งชิวขึ้นชื่อของโซนนี้ที่ต้องมาลองให...  4\n",
       "39992  ร้านที่ชื่อแปลก ตกแต่งสไตล์loft ได้อย่างลงตัว ...  4\n",
       "39993  นั่งกิน Bar B Q กันอยู่ มองไปทาง food court เห...  3\n",
       "39994  \"อร่อย ขนมจีบ ซาลาเปา\" ขนมจีบลูกใหญ่ กับซาลาเป...  4\n",
       "39995  รู้จักร้านนี้จากวงใน ร้านอยู่ในอาคารพาณิชย์ตรง...  4\n",
       "39996  ร้านซูชิอาหารญี่ปุ่น อยู่ตรงสะพานลอย เกษตรประต...  4\n",
       "39997  \"Cantina Wine Bar & Italian Kitchen\" ร้านเล็กๆ...  5\n",
       "39998  ร้านเค้กน่ารักๆ ตรงชั้นล่างของห้างเซ็นทรัลลาดพ...  3\n",
       "39999  วันนี้มากินกันไกลถึงแม่สอดจังหวัดตากติดกับชายแ...  3\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = df[:][:40000]\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(len(demo)):\n",
    "    train.append((demo[0][i], demo[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_htmlTags(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext\n",
    "    \n",
    "def isValidWord(text):\n",
    "    dic = {text[0]:1}\n",
    "    for c in text[1:]:\n",
    "        if c not in dic:\n",
    "            return True\n",
    "        else:\n",
    "            dic[c] += 1\n",
    "    if dic[text[0]] > 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def tokenize(review):\n",
    "    \n",
    "#     tags = tltk.nlp.pos_tag(review.replace(\"\\n\", \"\"))\n",
    "    noSpace = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, cutKumKrub(review)))\n",
    "    finalWord = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, noSpace))\n",
    "\n",
    "#     # Filter parts of speech of text\n",
    "#     tags = tltk.nlp.pos_tag(remove_htmlTags(review.replace(\"\\n\", \"\")))\n",
    "#     finalWord = []\n",
    "#     filteredTags = {'NOUN', 'VERB', 'ADJ','ADV', 'AUX', 'PART'}\n",
    "#     for sentence in tags:\n",
    "#         for word, tag in sentence:\n",
    "#             if tag in filteredTags:\n",
    "#                 if len(word) > 1 and isValidWord(word):\n",
    "#                     finalWord.append(remove_htmlTags(word))\n",
    "    return finalWord\n",
    "\n",
    "# tokenize(train[0][0])\n",
    "# train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "# vocabulary = set(chain(*[tokenize(i[0].lower()) for i in train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CHARS_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f702984ce339>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-9a08ecc85fb4>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#     tags = tltk.nlp.pos_tag(review.replace(\"\\n\", \"\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mnoSpace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutKumKrub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mfinalWord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoSpace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-6b0c1ff35149>\u001b[0m in \u001b[0;36mcutKumKrub\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdf_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_n_gram_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;31m# arg is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66645)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-6b0c1ff35149>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdf_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_n_gram_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CHARS_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenize(test_set.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/40000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CHARS_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-92a129af27c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcorpus_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-9a08ecc85fb4>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#     tags = tltk.nlp.pos_tag(review.replace(\"\\n\", \"\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mnoSpace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutKumKrub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mfinalWord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoSpace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-6b0c1ff35149>\u001b[0m in \u001b[0;36mcutKumKrub\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdf_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_n_gram_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;31m# arg is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66645)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-6b0c1ff35149>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_test_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_test_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCHARS_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdf_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_n_gram_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_test_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CHARS_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "corpus_test = []\n",
    "for i in range(len(test_set)):\n",
    "    print(str(i+1) + \"/\" + str(len(train)))\n",
    "    corpus_test.append(tokenize(test_set.iloc[i]))\n",
    "\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-11dcaa38ea1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpickle_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"corpus_test.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# pickle_out = open(\"corpus3.pickle\",\"wb\")\n",
    "# pickle.dump(corpus, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"corpus_test.pickle\",\"wb\")\n",
    "pickle.dump(corpus_test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "corpus = corpus[:40000]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"corpus4.pickle\",\"rb\")\n",
    "corpus = pickle.load(pickle_in)\n",
    "len(corpus)\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus\n",
    "# corpus2 = corpus[:1000]\n",
    "newcor = corpus\n",
    "test = corpus_test\n",
    "# tltk.nlp.pos_tag(train[0][0])\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mytok(mylist):\n",
    "    for i in range(len(mylist)):\n",
    "        mylist[i] = mylist[i].lower()\n",
    "    return mylist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "tfidf = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=mytok, binary = True)\n",
    "tfidf_matrix = tfidf.fit_transform(newcor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40000x167678 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3585680 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# idf = tfidf.idf_\n",
    "# print (tfidf.get_feature_names(), idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corpus = [\n",
    "#     tokenize(df[0][0]),\n",
    "#     tokenize(df[0][1]),\n",
    "#     tokenize(df[0][2])\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekapolc/.env/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9a88f86aa33a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    550\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0midx_slice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                         self._em_step(X[idx_slice, :], total_samples=n_samples,\n\u001b[1;32m--> 552\u001b[1;33m                                       batch_update=False, parallel=parallel)\n\u001b[0m\u001b[0;32m    553\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;31m# batch update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[1;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;31m# update `component_` related variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         self.exp_dirichlet_component_ = np.exp(\n\u001b[1;32m--> 450\u001b[1;33m             _dirichlet_expectation_2d(self.components_))\n\u001b[0m\u001b[0;32m    451\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_batch_iter_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# pca = PCA(n_components = 300)\n",
    "\n",
    "# x_train = pca.fit_transform(x_train)\n",
    "svd = TruncatedSVD(n_components=300, n_iter=10, random_state=42)\n",
    "x_train = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for i in range(40000):\n",
    "    y_train.append(train[i][1])\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 300)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "# tfidf_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_matrix = tfidf.transform(newcor[36000:])\n",
    "# print(tfidf_matrix)\n",
    "x_test = svd.transform(tfidf_matrix)\n",
    "\n",
    "tfidf_matrix = tfidf.transform(test)\n",
    "x_test_r = svd.transform(tfidf_matrix)\n",
    "y_test = []\n",
    "\n",
    "for i in range(36000,40000):\n",
    "    y_test.append(train[i][1])\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# predictions = classifier.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 300)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train.mean()\n",
    "# predictions\n",
    "# f1_score(y_test, predictions, average='macro')\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18891432308698497"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = linearClassifier.predict(x_test)\n",
    "predictions\n",
    "f1_score(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "rate = 0.3\n",
    "\n",
    "def get_feedforward_nn():\n",
    "  input1 = Input(shape=(300,))\n",
    "  x = Dense(100, activation='relu')(input1)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(10, activation='relu')(x)\n",
    "  x = Dropout(0.2)(x)  \n",
    "  out = Dense(1, activation='relu')(x)\n",
    "\n",
    "  model = Model(inputs=input1, outputs=out)\n",
    "  model.compile(optimizer=Adam(),\n",
    "                loss='mean_squared_error',\n",
    "                metrics=[f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 300)\n",
      "train with 20 epochs and 32 batch size\n",
      "Train on 40000 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "39712/40000 [============================>.] - ETA: 0s - loss: 1.7750 - f1: nanEpoch 00000: val_loss improved from inf to 0.55674, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 1.7702 - f1: nan - val_loss: 0.5567 - val_f1: 1.0000\n",
      "Epoch 2/20\n",
      "39744/40000 [============================>.] - ETA: 0s - loss: 1.0279 - f1: 1.0000Epoch 00001: val_loss improved from 0.55674 to 0.52102, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 1.0284 - f1: 1.0000 - val_loss: 0.5210 - val_f1: 1.0000\n",
      "Epoch 3/20\n",
      "39872/40000 [============================>.] - ETA: 0s - loss: 0.8618 - f1: 1.0000Epoch 00002: val_loss improved from 0.52102 to 0.51725, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.8619 - f1: 1.0000 - val_loss: 0.5173 - val_f1: 1.0000\n",
      "Epoch 4/20\n",
      "39520/40000 [============================>.] - ETA: 0s - loss: 0.7227 - f1: 1.0000Epoch 00003: val_loss improved from 0.51725 to 0.49149, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.7223 - f1: 1.0000 - val_loss: 0.4915 - val_f1: 1.0000\n",
      "Epoch 5/20\n",
      "39520/40000 [============================>.] - ETA: 0s - loss: 0.6396 - f1: 1.0000Epoch 00004: val_loss improved from 0.49149 to 0.48056, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.6388 - f1: 1.0000 - val_loss: 0.4806 - val_f1: 1.0000\n",
      "Epoch 6/20\n",
      "39968/40000 [============================>.] - ETA: 0s - loss: 0.5731 - f1: 1.0000Epoch 00005: val_loss improved from 0.48056 to 0.46077, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.5732 - f1: 1.0000 - val_loss: 0.4608 - val_f1: 1.0000\n",
      "Epoch 7/20\n",
      "39360/40000 [============================>.] - ETA: 0s - loss: 0.5332 - f1: 1.0000Epoch 00006: val_loss improved from 0.46077 to 0.45709, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.5337 - f1: 1.0000 - val_loss: 0.4571 - val_f1: 1.0000\n",
      "Epoch 8/20\n",
      "39424/40000 [============================>.] - ETA: 0s - loss: 0.5051 - f1: 1.0000Epoch 00007: val_loss improved from 0.45709 to 0.44106, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.5049 - f1: 1.0000 - val_loss: 0.4411 - val_f1: 1.0000\n",
      "Epoch 9/20\n",
      "39456/40000 [============================>.] - ETA: 0s - loss: 0.4895 - f1: 1.0000Epoch 00008: val_loss improved from 0.44106 to 0.42847, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.4896 - f1: 1.0000 - val_loss: 0.4285 - val_f1: 1.0000\n",
      "Epoch 10/20\n",
      "39456/40000 [============================>.] - ETA: 0s - loss: 0.4772 - f1: 1.0000Epoch 00009: val_loss improved from 0.42847 to 0.42364, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.4769 - f1: 1.0000 - val_loss: 0.4236 - val_f1: 1.0000\n",
      "Epoch 11/20\n",
      "39456/40000 [============================>.] - ETA: 0s - loss: 0.4631 - f1: 1.0000Epoch 00010: val_loss improved from 0.42364 to 0.40898, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.4625 - f1: 1.0000 - val_loss: 0.4090 - val_f1: 1.0000\n",
      "Epoch 12/20\n",
      "39520/40000 [============================>.] - ETA: 0s - loss: 0.4553 - f1: 1.0000Epoch 00011: val_loss improved from 0.40898 to 0.39797, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.4553 - f1: 1.0000 - val_loss: 0.3980 - val_f1: 1.0000\n",
      "Epoch 13/20\n",
      "39744/40000 [============================>.] - ETA: 0s - loss: 0.4468 - f1: 1.0000Epoch 00012: val_loss improved from 0.39797 to 0.38901, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.4470 - f1: 1.0000 - val_loss: 0.3890 - val_f1: 1.0000\n",
      "Epoch 14/20\n",
      "39936/40000 [============================>.] - ETA: 0s - loss: 0.4422 - f1: 1.0000Epoch 00013: val_loss improved from 0.38901 to 0.38518, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.4423 - f1: 1.0000 - val_loss: 0.3852 - val_f1: 1.0000\n",
      "Epoch 15/20\n",
      "39392/40000 [============================>.] - ETA: 0s - loss: 0.4364 - f1: 0.9999Epoch 00014: val_loss improved from 0.38518 to 0.37373, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n",
      "40000/40000 [==============================] - 4s - loss: 0.4365 - f1: 0.9999 - val_loss: 0.3737 - val_f1: 1.0000\n",
      "Epoch 16/20\n",
      "39968/40000 [============================>.] - ETA: 0s - loss: 0.4284 - f1: 0.9999Epoch 00015: val_loss improved from 0.37373 to 0.36871, saving model to ~/workspace/model/model_weight_feedforward_nn2.h5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to flush file's cached information (file write failed: time = Sat Mar 10 20:27:42 2018\n, filename = '~/workspace/model/model_weight_feedforward_nn2.h5', file descriptor = 45, errno = 28, error message = 'No space left on device', buf = 0xe135110, total write size = 3152, bytes this sub-write = 3152, bytes actually written = 18446744073709551615, offset = 139264)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-224-771818c90466>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m   model_feedforward_nn.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m     34\u001b[0m                            \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list_feedforward_nn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                            validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1201\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    413\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite)\u001b[0m\n\u001b[0;32m   2583\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m         \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2585\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2586\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.flush\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to flush file's cached information (file write failed: time = Sat Mar 10 20:27:42 2018\n, filename = '~/workspace/model/model_weight_feedforward_nn2.h5', file descriptor = 45, errno = 28, error message = 'No space left on device', buf = 0xe135110, total write size = 3152, bytes this sub-write = 3152, bytes actually written = 18446744073709551615, offset = 139264)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# This is called to clear the original model session in order to use TensorBoard\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# Path to save model parameters\n",
    "weight_path_feedforward_nn='~/workspace/model/model_weight_feedforward_nn2.h5'\n",
    "\n",
    "# Training callbacks list. TensorBoard() write logs for tensorboard GUI. \n",
    "# ModelCheckpoint() writes the resulting model.\n",
    "# Note that writing to disk takes time (longer than model training time). \n",
    "# For other sections, you might not writing any files to disk \n",
    "# or write only the graph for TensorBoard.\n",
    "callbacks_list_feedforward_nn = [\n",
    "        TensorBoard(log_dir='~/workspace/model/Graph/ff2', histogram_freq=1, write_graph=True, write_grads=True),\n",
    "        ModelCheckpoint(\n",
    "            weight_path_feedforward_nn,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        )\n",
    "  ]\n",
    "\n",
    "print(x_test.shape)\n",
    "verbose = 1\n",
    "model_feedforward_nn = get_feedforward_nn()\n",
    "train_params = [(20, 32)]\n",
    "for (epochs, batch_size) in train_params:\n",
    "  print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
    "  model_feedforward_nn.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
    "                           callbacks=callbacks_list_feedforward_nn,\n",
    "                           validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# from keras.layers import Dropout\n",
    "\n",
    "# def get_nn_with_dropout():\n",
    "\n",
    "#     rate = 0.1\n",
    "    \n",
    "#     input1 = Input(shape=(21,))\n",
    "#     x = Dense(100, activation='relu')(input1)\n",
    "#     x = Dropout(rate)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(rate)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(rate)(x)\n",
    "#     out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#     model = Model(inputs=input1, outputs=out)\n",
    "#     model.compile(optimizer=Adam(),\n",
    "#                 loss='binary_crossentropy',\n",
    "#                 metrics=['acc'])\n",
    "#     return model\n",
    "\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "\n",
    "################################################################################\n",
    "# Write a function to evaluate your model. Your function must make prediction  #\n",
    "# using the input model and return f-score, precision, and recall of the model.#\n",
    "# You can make predictions by calling model.predict().                         #\n",
    "################################################################################\n",
    "def evaluate(x_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Evaluate model on the splitted 10 percent testing set.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "#     #map probability to class\n",
    "#     prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "#     y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
    "    y_pred = np.rint(y_pred).astype(int) \n",
    "    print(y_pred.T[0][300:400])\n",
    "    print(y_test[300:400])\n",
    "    f1score = f1_score(y_test,y_pred.T[0], average='micro')\n",
    "#     precision = precision_score(y_test,y_pred,average='macro')\n",
    "#     recall = recall_score(y_test,y_pred,average='macro')\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 3 4 4 4 4 4 3 4 4 4 4 3 3 4 4 4 4 3 3 3 4 4 4 4 4 4 4 3 3 4 4 4 4 3 2\n",
      " 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 3 5 4 4 3 4 4 4 4 4 2 4 3 4 3 4 4 4 4 4\n",
      " 3 4 2 4 4 4 4 4 3 3 4 4 4 4 3 4 4 4 4 4 4 3 4 4 4 3]\n",
      "[3 4 3 4 4 4 5 4 4 3 4 4 5 4 2 3 5 5 4 2 3 4 4 3 4 5 4 4 4 3 4 4 4 3 4 2 1\n",
      " 3 4 4 3 5 2 4 3 5 5 4 4 5 5 3 4 4 4 5 3 5 4 4 3 3 3 3 3 4 2 3 3 4 4 5 4 4\n",
      " 3 4 1 3 4 4 5 5 3 3 5 3 4 4 3 3 4 4 4 3 5 3 3 4 5 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59599999999999997"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(x_test.shape)\n",
    "evaluate(x_test, y_test, model_feedforward_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_res = model_feedforward_nn.predict(x_test_r)\n",
    "\n",
    "#     #map probability to class\n",
    "#     prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "#     y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
    "y_res = np.rint(y_res).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, ..., 4, 4, 3])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = y_res.T[0]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewID  rating\n",
       "0         1       4\n",
       "1         2       3\n",
       "2         3       3\n",
       "3         4       4\n",
       "4         5       4\n",
       "5         6       4\n",
       "6         7       4\n",
       "7         8       3\n",
       "8         9       4\n",
       "9        10       4"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.DataFrame({\"reviewID\": np.arange(1,len(res)+1),\"rating\": res}, columns=[\"reviewID\", \"rating\"])\n",
    "df_res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_res.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
