{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run setup code\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tltk\n",
    "tltk.pos_load()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the preprocessed data\n",
    "best_processed_path = 'w_review_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ซ': 104, ',': 13, '๔': 169, 'G': 40, \"'\": 8, '?': 32, '๐': 165, 'q': 82, '\\ufeff': 177, 'k': 75, 'i': 73, 'ื': 147, '๘': 173, 'ั': 141, '8': 25, 'ว': 131, 'D': 37, 'ๅ': 156, '้': 160, 'ศ': 132, 'Q': 50, 'n': 78, 'ฃ': 96, 'ฉ': 102, '๓': 168, ')': 10, '๒': 167, 'S': 52, 'แ': 152, 'ก': 94, 'ุ': 148, 'ง': 100, ':': 27, '.': 15, ';': 28, 'ช': 103, '’': 176, 'ำ': 143, '\\n': 0, 'ึ': 146, 'K': 44, '4': 21, '(': 9, 'O': 48, 'ข': 95, '๖': 171, '่': 159, 'N': 47, '๊': 161, '<': 29, 'b': 66, ']': 62, '๋': 162, 't': 85, 'า': 142, 'X': 57, '๑': 166, 'ฏ': 108, 'c': 67, 'a': 65, 'ฅ': 98, 'u': 86, 'ท': 116, 'ษ': 133, 'อ': 137, '๕': 170, 'ร': 128, 'ฑ': 110, '7': 24, 'ฤ': 129, 'ไ': 155, 'ฐ': 109, 'ถ': 115, 'j': 74, 'p': 81, 'ส': 134, 'ด': 113, 'T': 53, '}': 92, 'ู': 149, 'd': 68, 'ฬ': 136, '3': 20, 'ฺ': 150, 'ธ': 117, 'z': 91, 'r': 83, 'ฆ': 99, 'ะ': 140, 'ภ': 125, 'ฮ': 138, 'f': 70, 'E': 38, 'ฝ': 122, 'B': 35, '&': 7, '[': 60, '๙': 174, 'ห': 135, 'l': 76, '@': 33, 'M': 46, 'ผ': 121, 'ฒ': 111, 'v': 87, 'ํ': 164, 'เ': 151, '5': 22, '^': 63, 'F': 39, 'ฎ': 107, 'ล': 130, 'A': 34, 'ฯ': 139, '=': 30, 'ฟ': 124, 'บ': 119, 'P': 49, '#': 4, '_': 64, '์': 163, '6': 23, '*': 11, 'จ': 101, 'ิ': 144, '\"': 3, 'ค': 97, 'Z': 59, 'ญ': 106, 'g': 71, '$': 5, 'W': 56, '>': 31, 'ป': 120, 'ฌ': 105, 'ๆ': 157, '0': 17, 'ี': 145, '/': 16, '‘': 175, 'other': 80, 'U': 54, 'h': 72, 'H': 41, 'โ': 153, '็': 158, 'ต': 114, ' ': 1, 'w': 88, 'ณ': 112, '-': 14, 'm': 77, '!': 2, 'ย': 127, 'ใ': 154, 'x': 89, 'o': 79, '9': 26, '\\\\': 61, 'L': 45, '+': 12, '~': 93, 'y': 90, '2': 19, 'ม': 126, 'J': 43, 'V': 55, 'พ': 123, '%': 6, 'I': 42, '1': 18, 's': 84, 'R': 51, 'C': 36, 'e': 69, 'Y': 58, 'น': 118, '๗': 172}\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "# Create a character map\n",
    "CHARS = [\n",
    "  '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
    "  ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "  '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n",
    "  'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "  'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_',\n",
    "  'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "  'n', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "  'z', '}', '~', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช',\n",
    "  'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท',\n",
    "  'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ',\n",
    "  'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า',\n",
    "  'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ',\n",
    "  'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๐', '๑', '๒', '๓',\n",
    "  '๔', '๕', '๖', '๗', '๘', '๙', '‘', '’', '\\ufeff'\n",
    "]\n",
    "CHARS_MAP = {v: k for k, v in enumerate(CHARS)}\n",
    "print(CHARS_MAP)\n",
    "print(len(CHARS_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding,Dense, Conv1D, Flatten, TimeDistributed, Dropout\n",
    "from keras.layers import Input, GRU, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "# def get_my_best_model2():\n",
    "#     input1 = Input(shape=(21,))\n",
    "#     x = Embedding(178,8)(input1)\n",
    "#     x = Conv1D(100,5,strides=1,activation='relu',padding=\"same\")(x)\n",
    "#     x = TimeDistributed(Dense(5))(x)ฅ\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(0.05)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(0.05)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(0.05)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     out = Dense(1, activation='sigmoid')(x)\n",
    "#     model = Model(inputs=input1, outputs=out)\n",
    "#     model.compile(optimizer=Adam(),\n",
    "#                  loss='binary_crossentropy',\n",
    "#                  metrics=['acc'])          \n",
    "#     return model\n",
    "\n",
    "def get_my_best_model():\n",
    "    input1 = Input(shape=(21,))\n",
    "    x = Embedding(178,8)(input1)\n",
    "    x = Conv1D(100,5,strides=1,activation='relu',padding=\"same\")(x)\n",
    "    x = TimeDistributed(Dense(5))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])          \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/data/model_best.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7e652a59b208>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mweight_path_my_best_model2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/data/model_best.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmy_best_model2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_my_best_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmy_best_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_path_my_best_model2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#my_best_model2.make_predict_function()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmy_best_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   2611\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2612\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2613\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2614\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2615\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/data/model_best.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "weight_path_my_best_model2='/data/model_best.h5'\n",
    "my_best_model2 = get_my_best_model()\n",
    "my_best_model2.load_weights(weight_path_my_best_model2)\n",
    "#my_best_model2.make_predict_function()\n",
    "my_best_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(best_processed_path, sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_n_gram_df(df, n_pad):\n",
    "  \"\"\"\n",
    "  Given an input dataframe, create a feature dataframe of shifted characters\n",
    "  Input:\n",
    "  df: timeseries of size (N)\n",
    "  n_pad: the number of context. For a given character at position [idx],\n",
    "    character at position [idx-n_pad/2 : idx+n_pad/2] will be used \n",
    "    as features for that character.\n",
    "  \n",
    "  Output:\n",
    "  dataframe of size (N * n_pad) which each row contains the character, \n",
    "    n_pad_2 characters to the left, and n_pad_2 characters to the right\n",
    "    of that character.\n",
    "  \"\"\"\n",
    "  n_pad_2 = int((n_pad - 1)/2)\n",
    "  for i in range(n_pad_2):\n",
    "      df['char-{}'.format(i+1)] = df[0].shift(i + 1)\n",
    "      df['char{}'.format(i+1)] = df[0].shift(-i - 1)\n",
    "  return df[n_pad_2: -n_pad_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "อาหารที่นี่เป็นอาหารจีนแคะที่หากินยากในบ้านเรา ตัวร้านตั้งอยู่ที่ถนนพุทธมณฑลสาย 3 ไปตาม ถ.ปิ่นเกล้า-นครชัยศรี เมื่อถึงพุทธมณฑลสาย 3 ก็เลี้ยวเข้าไปประมาณ 500 เมตร ร้านอยู่ทางซ้ายมือค่ะ มีคนบอกมาว่าความพิเศษของร้านนี้คือกุ๊กเก่าและเป็นกุ๊กรุ่นสุดท้ายจาก \"ฮก ลก ซิ่ว” ภัตตาคารจีนชื่อดังย่านราชประสงค์ ที่เลิกกิจการไปแล้ว ต้องคนที่อายุเลข 5 ขึ้นไปจึงจะเคยกิน ฮก ลก ซิ่ว  จานเด็ดที่มีขายที่นี่แห่งเดียวในเมืองไทยคือ ปลาเต๋าเต้ย 2 ฤดู เป็นสูตรจากมาเลเซีย นอกนั้นก็มี ผัดผักน้ำมันหอย ไก่เบตง เคาหยก ปูทะเลซุปน้ำใสหม้อไฟ เต้าหู้แคระยัดไส้หม้อดิน และ ลูกชิ้นแคระ \n",
      "อาหารที่เราแนะนำคือไก่เบตง (คล้ายๆไก่แช่เหล้า) เสริฟพร้อมกับหอมเจียว และน้ำจิ้มน้ำพริกเผาสูตรเด็ดของทางร้าน \n",
      "เมนูข้าวผัดหนำเลียบก็อร่อยค่ะ ชอบมากๆ\n"
     ]
    }
   ],
   "source": [
    "word_test = [x for x in df[0][1]]\n",
    "print(''.join(word_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_test_df2 = pd.DataFrame(word_test)\n",
    "#print(word_test_df2)\n",
    "\n",
    "n_pad = 21\n",
    "n_pad_2 = int((n_pad - 1)/2)\n",
    "pad = [{0: ' '}]\n",
    "df_pad = pd.DataFrame(pad * n_pad_2)\n",
    "#print(df_pad)\n",
    "\n",
    "word_test_df2 = pd.concat((df_pad, word_test_df2, df_pad))\n",
    "#print(word_test_df2[0][:21])\n",
    "word_test_df2[0] = word_test_df2[0].map(lambda x: CHARS_MAP.get(x, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_context = create_n_gram_df(word_test_df2, n_pad=n_pad)\n",
    "\n",
    "char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
    "             ['char-' + str(i + 1) for i in range(n_pad_2)] + [0]\n",
    "\n",
    "# convert pandas dataframe to numpy array to feed to the model\n",
    "x_char = df_with_context[char_row].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = my_best_model2.predict(x_char)\n",
    "\n",
    "prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "y_pred = np.apply_along_axis(prob_to_class,1,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n",
      "701\n",
      "['อ', 'า', 'ห', 'า', 'ร', 'ท', 'ี', '่', 'น', 'ี', '่', 'เ', 'ป', '็', 'น', 'อ', 'า', 'ห', 'า', 'ร', 'จ', 'ี', 'นแ', 'ค', 'ะ', 'ท', 'ี', '่', 'ห', 'า', 'ก', 'ิ', 'น', 'ย', 'า', 'ก', 'ใ', 'น', 'บ', '้', 'า', 'น', 'เ', 'ร', 'า', ' ', 'ต', 'ั', 'ว', 'ร', '้', 'า', 'น', 'ต', 'ั', '้', 'ง', 'อ', 'ย', 'ู', '่', 'ท', 'ี', '่', 'ถ', 'น', 'น', 'พ', 'ุ', 'ท', 'ธมณ', 'ฑ', 'ล', 'ส', 'า', 'ย', ' ', '3', ' ', 'ไ', 'ป', 'ต', 'า', 'ม', ' ', 'ถ', '.', 'ป', 'ิ', '่', 'น', 'เ', 'ก', 'ล', '้', 'า', '-', 'น', 'ค', 'ร', 'ช', 'ั', 'ย', 'ศ', 'ร', 'ี', ' ', 'เ', 'ม', 'ื', '่', 'อ', 'ถ', 'ึง', 'พ', 'ุ', 'ท', 'ธ', 'มณ', 'ฑ', 'ล', 'ส', 'า', 'ย', ' ', '3', ' ', 'ก', '็', 'เ', 'ล', 'ี', '้', 'ย', 'ว', 'เ', 'ข', '้', 'า', 'ไ', 'ป', 'ป', 'ร', 'ะ', 'ม', 'า', 'ณ', ' ', '50', '0', ' ', 'เ', 'ม', 'ต', 'ร', ' ร', '้', 'า', 'น', 'อ', 'ย', 'ู', '่', 'ท', 'า', 'งซ', '้', 'า', 'ย', 'ม', 'ื', 'อ', 'ค', '่', 'ะ', ' ', 'ม', 'ี', 'ค', 'นบ', 'อ', 'กม', 'า', 'ว', '่', 'า', 'ค', 'ว', 'า', 'ม', 'พ', 'ิ', 'เ', 'ศ', 'ษ', 'ข', 'อ', 'ง', 'ร', '้', 'า', 'น', 'น', 'ี', '้', 'ค', 'ื', 'อ', 'ก', 'ุ', '๊', 'ก', 'เ', 'ก', '่', 'า', 'แ', 'ล', 'ะ', 'เ', 'ป', '็', 'น', 'ก', 'ุ', '๊', 'ก', 'ร', 'ุ', '่', 'น', 'ส', 'ุ', 'ด', 'ท', '้', 'าย', 'จ', 'า', 'ก ', '\"', 'ฮ', 'ก', ' ', 'ล', 'ก', ' ', 'ซ', 'ิ', '่', 'ว', '”', ' ', 'ภ', 'ั', 'ต', 'ต', 'า', 'ค', 'า', 'ร', 'จี', 'น', 'ช', 'ื', '่', 'อ', 'ดั', 'ง', 'ย', '่', 'า', 'น', 'รา', 'ช', 'ป', 'ร', 'ะ', 'ส', 'ง', 'ค', '์', ' ', 'ท', 'ี', '่', 'เ', 'ล', 'ิ', 'ก', 'ก', 'ิ', 'จ', 'ก', 'า', 'ร', 'ไ', 'ป', 'แ', 'ล', '้', 'ว', ' ', 'ต', '้', 'อ', 'ง', 'ค', 'น', 'ที', '่อ', 'า', 'ย', 'ุ', 'เ', 'ลข', ' ', '5', ' ', 'ข', 'ึ', '้', 'น', 'ไ', 'ป', 'จ', 'ึ', 'ง', 'จ', 'ะ', 'เ', 'ค', 'ย', 'ก', 'ิ', 'น', ' ', 'ฮ', 'ก', ' ', 'ล', 'ก', ' ', 'ซ', 'ิ', '่', 'ว', ' ', ' ', 'จ', 'า', 'น', 'เ', 'ด', '็', 'ด', 'ท', 'ี', '่', 'ม', 'ี', 'ข', 'า', 'ย', 'ท', 'ี', '่', 'น', 'ี', '่', 'แ', 'ห', '่', 'ง', 'เ', 'ด', 'ี', 'ย', 'ว', 'ใ', 'น', 'เ', 'ม', 'ื', 'อ', 'ง', 'ไ', 'ท', 'ย', 'ค', 'ื', 'อ', ' ป', 'ล', 'า', 'เต', '๋', 'า', 'เ', 'ต', '้', 'ย', ' ', '2', ' ', 'ฤ', 'ด', 'ู', ' ', 'เ', 'ป', '็', 'น', 'ส', 'ู', 'ต', 'ร', 'จ', 'า', 'ก', 'ม', 'า', 'เ', 'ล', 'เ', 'ซ', 'ี', 'ย', ' ', 'น', 'อ', 'ก', 'น', 'ั', '้', 'น', 'ก', '็', 'ม', 'ี', ' ', 'ผ', 'ั', 'ด', 'ผ', 'ั', 'ก', 'น', '้', 'ำ', 'ม', 'ั', 'น', 'ห', 'อ', 'ย', ' ', 'ไ', 'ก', '่เ', 'บ', 'ต', 'ง', ' เ', 'ค', 'า', 'ห', 'ย', 'ก', ' ', 'ป', 'ู', 'ท', 'ะ', 'เ', 'ล', 'ซ', 'ุ', 'ป', 'น', '้', 'ำ', 'ใ', 'ส', 'ห', 'ม', '้', 'อ', 'ไ', 'ฟ', ' ', 'เต้', 'า', 'ห', 'ู', '้', 'แ', 'ค', 'ร', 'ะ', 'ย', 'ั', 'ด', 'ไ', 'ส', '้', 'ห', 'ม', '้', 'อด', 'ิ', 'น', ' ', 'แ', 'ล', 'ะ', ' ', 'ล', 'ู', 'ก', 'ช', 'ิ', '้', 'น', 'แ', 'ค', 'ร', 'ะ', ' ', '\\n', 'อ', 'า', 'หา', 'ร', 'ท', 'ี', '่', 'เ', 'ร', 'า', 'แ', 'น', 'ะ', 'น', 'ำ', 'ค', 'ื', 'อ', 'ไ', 'ก', '่', 'เบ', 'ต', 'ง', ' (', 'ค', 'ล', '้', 'า', 'ย', 'ๆ', 'ไ', 'ก', '่', 'แ', 'ช', '่', 'เ', 'ห', 'ล', '้', 'า', ')', ' เ', 'ส', 'ร', 'ิ', 'ฟ', 'พ', 'ร', '้', 'อ', 'ม', 'ก', 'ั', 'บ', 'ห', 'อ', 'ม', 'เ', 'จ', 'ี', 'ย', 'ว', ' ', 'แ', 'ล', 'ะ', 'น', '้', 'ำจ', 'ิ', '้', 'ม', 'น', '้', 'ำ', 'พ', 'ร', 'ิ', 'ก', 'เ', 'ผ', 'า', 'ส', 'ู', 'ต', 'ร', 'เ', 'ด', '็', 'ด', 'ขอ', 'ง', 'ท', 'า', 'งร', '้', 'า', 'น', ' ', '\\n', 'เ', 'ม', 'น', 'ู', 'ข', '้', 'า', 'ว', 'ผ', 'ั', 'ด', 'ห', 'น', 'ำ', 'เ', 'ล', 'ี', 'ย', 'บ', 'ก', '็', 'อ', 'ร', '่', 'อ', 'ย', 'ค', '่', 'ะ', ' ', 'ช', 'อ', 'บ', 'ม', 'า', 'ก', 'ๆ']\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print(len(word_test))\n",
    "word_token = []\n",
    "word_tmp = ''\n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i] == 1):\n",
    "        word_token.append(word_tmp)\n",
    "        word_tmp = ''\n",
    "    word_tmp += word_test[i]\n",
    "else:\n",
    "    word_token.append(word_tmp)\n",
    "word_token = word_token[1:]\n",
    "print(word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cutKumKrub(string):\n",
    "    word_test = [x for x in string]\n",
    "    word_test_df2 = pd.DataFrame(word_test)\n",
    "\n",
    "    n_pad = 21\n",
    "    n_pad_2 = int((n_pad - 1)/2)\n",
    "    pad = [{0: ' '}]\n",
    "    df_pad = pd.DataFrame(pad * n_pad_2)\n",
    "\n",
    "    word_test_df2 = pd.concat((df_pad, word_test_df2, df_pad))\n",
    "    word_test_df2[0] = word_test_df2[0].map(lambda x: CHARS_MAP.get(x, 80))\n",
    "    \n",
    "    df_with_context = create_n_gram_df(word_test_df2, n_pad=n_pad)\n",
    "\n",
    "    char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
    "                 ['char-' + str(i + 1) for i in range(n_pad_2)] + [0]\n",
    "\n",
    "    # convert pandas dataframe to numpy array to feed to the model\n",
    "    x_char = df_with_context[char_row].as_matrix()\n",
    "    \n",
    "    y_pred = my_best_model2.predict(x_char)\n",
    "\n",
    "    prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "    y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
    "    \n",
    "    word_token = []\n",
    "    word_tmp = ''\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i] == 1):\n",
    "            word_token.append(word_tmp)\n",
    "            word_tmp = ''\n",
    "        word_tmp += word_test[i]\n",
    "    else:\n",
    "        word_token.append(word_tmp)\n",
    "    word_token = word_token[1:]\n",
    "    return word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeLabel(review, rating):\n",
    "    noSpace = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, cutKumKrub(review)))\n",
    "    cleaned = list(filter(lambda x: len(x.replace(\" \\n\", \"\")) > 0 and len(x.replace(\")\", \"\")) > 0, noSpace)) \n",
    "    for i in range(len(cleaned)):\n",
    "        cleaned[i] = cleaned[i].replace(\"\\n\", \"\")\n",
    "        cleaned[i] = cleaned[i].replace(\"(\", \"\")\n",
    "        cleaned[i] = cleaned[i].replace(\")\", \"\")\n",
    "    finalWord = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, cleaned))\n",
    "    label = [int(rating)] * len(cleaned)\n",
    "    training_data = list(zip(cleaned, label))\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('อ', 4),\n",
       " ('า', 4),\n",
       " ('ห', 4),\n",
       " ('า', 4),\n",
       " ('ร', 4),\n",
       " ('ท', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('น', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('เ', 4),\n",
       " ('ป', 4),\n",
       " ('็', 4),\n",
       " ('น', 4),\n",
       " ('อ', 4),\n",
       " ('า', 4),\n",
       " ('ห', 4),\n",
       " ('า', 4),\n",
       " ('ร', 4),\n",
       " ('จ', 4),\n",
       " ('ี', 4),\n",
       " ('นแ', 4),\n",
       " ('ค', 4),\n",
       " ('ะ', 4),\n",
       " ('ท', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('ห', 4),\n",
       " ('า', 4),\n",
       " ('ก', 4),\n",
       " ('ิ', 4),\n",
       " ('น', 4),\n",
       " ('ย', 4),\n",
       " ('า', 4),\n",
       " ('ก', 4),\n",
       " ('ใ', 4),\n",
       " ('น', 4),\n",
       " ('บ', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('น', 4),\n",
       " ('เ', 4),\n",
       " ('ร', 4),\n",
       " ('า', 4),\n",
       " ('ต', 4),\n",
       " ('ั', 4),\n",
       " ('ว', 4),\n",
       " ('ร', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('น', 4),\n",
       " ('ต', 4),\n",
       " ('ั', 4),\n",
       " ('้', 4),\n",
       " ('ง', 4),\n",
       " ('อ', 4),\n",
       " ('ย', 4),\n",
       " ('ู', 4),\n",
       " ('่', 4),\n",
       " ('ท', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('ถ', 4),\n",
       " ('น', 4),\n",
       " ('น', 4),\n",
       " ('พ', 4),\n",
       " ('ุ', 4),\n",
       " ('ท', 4),\n",
       " ('ธมณ', 4),\n",
       " ('ฑ', 4),\n",
       " ('ล', 4),\n",
       " ('ส', 4),\n",
       " ('า', 4),\n",
       " ('ย', 4),\n",
       " ('3', 4),\n",
       " ('ไ', 4),\n",
       " ('ป', 4),\n",
       " ('ต', 4),\n",
       " ('า', 4),\n",
       " ('ม', 4),\n",
       " ('ถ', 4),\n",
       " ('.', 4),\n",
       " ('ป', 4),\n",
       " ('ิ', 4),\n",
       " ('่', 4),\n",
       " ('น', 4),\n",
       " ('เ', 4),\n",
       " ('ก', 4),\n",
       " ('ล', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('-', 4),\n",
       " ('น', 4),\n",
       " ('ค', 4),\n",
       " ('ร', 4),\n",
       " ('ช', 4),\n",
       " ('ั', 4),\n",
       " ('ย', 4),\n",
       " ('ศ', 4),\n",
       " ('ร', 4),\n",
       " ('ี', 4),\n",
       " ('เ', 4),\n",
       " ('ม', 4),\n",
       " ('ื', 4),\n",
       " ('่', 4),\n",
       " ('อ', 4),\n",
       " ('ถ', 4),\n",
       " ('ึง', 4),\n",
       " ('พ', 4),\n",
       " ('ุ', 4),\n",
       " ('ท', 4),\n",
       " ('ธ', 4),\n",
       " ('มณ', 4),\n",
       " ('ฑ', 4),\n",
       " ('ล', 4),\n",
       " ('ส', 4),\n",
       " ('า', 4),\n",
       " ('ย', 4),\n",
       " ('3', 4),\n",
       " ('ก', 4),\n",
       " ('็', 4),\n",
       " ('เ', 4),\n",
       " ('ล', 4),\n",
       " ('ี', 4),\n",
       " ('้', 4),\n",
       " ('ย', 4),\n",
       " ('ว', 4),\n",
       " ('เ', 4),\n",
       " ('ข', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('ไ', 4),\n",
       " ('ป', 4),\n",
       " ('ป', 4),\n",
       " ('ร', 4),\n",
       " ('ะ', 4),\n",
       " ('ม', 4),\n",
       " ('า', 4),\n",
       " ('ณ', 4),\n",
       " ('50', 4),\n",
       " ('0', 4),\n",
       " ('เ', 4),\n",
       " ('ม', 4),\n",
       " ('ต', 4),\n",
       " ('ร', 4),\n",
       " (' ร', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('น', 4),\n",
       " ('อ', 4),\n",
       " ('ย', 4),\n",
       " ('ู', 4),\n",
       " ('่', 4),\n",
       " ('ท', 4),\n",
       " ('า', 4),\n",
       " ('งซ', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('ย', 4),\n",
       " ('ม', 4),\n",
       " ('ื', 4),\n",
       " ('อ', 4),\n",
       " ('ค', 4),\n",
       " ('่', 4),\n",
       " ('ะ', 4),\n",
       " ('ม', 4),\n",
       " ('ี', 4),\n",
       " ('ค', 4),\n",
       " ('นบ', 4),\n",
       " ('อ', 4),\n",
       " ('กม', 4),\n",
       " ('า', 4),\n",
       " ('ว', 4),\n",
       " ('่', 4),\n",
       " ('า', 4),\n",
       " ('ค', 4),\n",
       " ('ว', 4),\n",
       " ('า', 4),\n",
       " ('ม', 4),\n",
       " ('พ', 4),\n",
       " ('ิ', 4),\n",
       " ('เ', 4),\n",
       " ('ศ', 4),\n",
       " ('ษ', 4),\n",
       " ('ข', 4),\n",
       " ('อ', 4),\n",
       " ('ง', 4),\n",
       " ('ร', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('น', 4),\n",
       " ('น', 4),\n",
       " ('ี', 4),\n",
       " ('้', 4),\n",
       " ('ค', 4),\n",
       " ('ื', 4),\n",
       " ('อ', 4),\n",
       " ('ก', 4),\n",
       " ('ุ', 4),\n",
       " ('๊', 4),\n",
       " ('ก', 4),\n",
       " ('เ', 4),\n",
       " ('ก', 4),\n",
       " ('่', 4),\n",
       " ('า', 4),\n",
       " ('แ', 4),\n",
       " ('ล', 4),\n",
       " ('ะ', 4),\n",
       " ('เ', 4),\n",
       " ('ป', 4),\n",
       " ('็', 4),\n",
       " ('น', 4),\n",
       " ('ก', 4),\n",
       " ('ุ', 4),\n",
       " ('๊', 4),\n",
       " ('ก', 4),\n",
       " ('ร', 4),\n",
       " ('ุ', 4),\n",
       " ('่', 4),\n",
       " ('น', 4),\n",
       " ('ส', 4),\n",
       " ('ุ', 4),\n",
       " ('ด', 4),\n",
       " ('ท', 4),\n",
       " ('้', 4),\n",
       " ('าย', 4),\n",
       " ('จ', 4),\n",
       " ('า', 4),\n",
       " ('ก ', 4),\n",
       " ('\"', 4),\n",
       " ('ฮ', 4),\n",
       " ('ก', 4),\n",
       " ('ล', 4),\n",
       " ('ก', 4),\n",
       " ('ซ', 4),\n",
       " ('ิ', 4),\n",
       " ('่', 4),\n",
       " ('ว', 4),\n",
       " ('”', 4),\n",
       " ('ภ', 4),\n",
       " ('ั', 4),\n",
       " ('ต', 4),\n",
       " ('ต', 4),\n",
       " ('า', 4),\n",
       " ('ค', 4),\n",
       " ('า', 4),\n",
       " ('ร', 4),\n",
       " ('จี', 4),\n",
       " ('น', 4),\n",
       " ('ช', 4),\n",
       " ('ื', 4),\n",
       " ('่', 4),\n",
       " ('อ', 4),\n",
       " ('ดั', 4),\n",
       " ('ง', 4),\n",
       " ('ย', 4),\n",
       " ('่', 4),\n",
       " ('า', 4),\n",
       " ('น', 4),\n",
       " ('รา', 4),\n",
       " ('ช', 4),\n",
       " ('ป', 4),\n",
       " ('ร', 4),\n",
       " ('ะ', 4),\n",
       " ('ส', 4),\n",
       " ('ง', 4),\n",
       " ('ค', 4),\n",
       " ('์', 4),\n",
       " ('ท', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('เ', 4),\n",
       " ('ล', 4),\n",
       " ('ิ', 4),\n",
       " ('ก', 4),\n",
       " ('ก', 4),\n",
       " ('ิ', 4),\n",
       " ('จ', 4),\n",
       " ('ก', 4),\n",
       " ('า', 4),\n",
       " ('ร', 4),\n",
       " ('ไ', 4),\n",
       " ('ป', 4),\n",
       " ('แ', 4),\n",
       " ('ล', 4),\n",
       " ('้', 4),\n",
       " ('ว', 4),\n",
       " ('ต', 4),\n",
       " ('้', 4),\n",
       " ('อ', 4),\n",
       " ('ง', 4),\n",
       " ('ค', 4),\n",
       " ('น', 4),\n",
       " ('ที', 4),\n",
       " ('่อ', 4),\n",
       " ('า', 4),\n",
       " ('ย', 4),\n",
       " ('ุ', 4),\n",
       " ('เ', 4),\n",
       " ('ลข', 4),\n",
       " ('5', 4),\n",
       " ('ข', 4),\n",
       " ('ึ', 4),\n",
       " ('้', 4),\n",
       " ('น', 4),\n",
       " ('ไ', 4),\n",
       " ('ป', 4),\n",
       " ('จ', 4),\n",
       " ('ึ', 4),\n",
       " ('ง', 4),\n",
       " ('จ', 4),\n",
       " ('ะ', 4),\n",
       " ('เ', 4),\n",
       " ('ค', 4),\n",
       " ('ย', 4),\n",
       " ('ก', 4),\n",
       " ('ิ', 4),\n",
       " ('น', 4),\n",
       " ('ฮ', 4),\n",
       " ('ก', 4),\n",
       " ('ล', 4),\n",
       " ('ก', 4),\n",
       " ('ซ', 4),\n",
       " ('ิ', 4),\n",
       " ('่', 4),\n",
       " ('ว', 4),\n",
       " ('จ', 4),\n",
       " ('า', 4),\n",
       " ('น', 4),\n",
       " ('เ', 4),\n",
       " ('ด', 4),\n",
       " ('็', 4),\n",
       " ('ด', 4),\n",
       " ('ท', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('ม', 4),\n",
       " ('ี', 4),\n",
       " ('ข', 4),\n",
       " ('า', 4),\n",
       " ('ย', 4),\n",
       " ('ท', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('น', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('แ', 4),\n",
       " ('ห', 4),\n",
       " ('่', 4),\n",
       " ('ง', 4),\n",
       " ('เ', 4),\n",
       " ('ด', 4),\n",
       " ('ี', 4),\n",
       " ('ย', 4),\n",
       " ('ว', 4),\n",
       " ('ใ', 4),\n",
       " ('น', 4),\n",
       " ('เ', 4),\n",
       " ('ม', 4),\n",
       " ('ื', 4),\n",
       " ('อ', 4),\n",
       " ('ง', 4),\n",
       " ('ไ', 4),\n",
       " ('ท', 4),\n",
       " ('ย', 4),\n",
       " ('ค', 4),\n",
       " ('ื', 4),\n",
       " ('อ', 4),\n",
       " (' ป', 4),\n",
       " ('ล', 4),\n",
       " ('า', 4),\n",
       " ('เต', 4),\n",
       " ('๋', 4),\n",
       " ('า', 4),\n",
       " ('เ', 4),\n",
       " ('ต', 4),\n",
       " ('้', 4),\n",
       " ('ย', 4),\n",
       " ('2', 4),\n",
       " ('ฤ', 4),\n",
       " ('ด', 4),\n",
       " ('ู', 4),\n",
       " ('เ', 4),\n",
       " ('ป', 4),\n",
       " ('็', 4),\n",
       " ('น', 4),\n",
       " ('ส', 4),\n",
       " ('ู', 4),\n",
       " ('ต', 4),\n",
       " ('ร', 4),\n",
       " ('จ', 4),\n",
       " ('า', 4),\n",
       " ('ก', 4),\n",
       " ('ม', 4),\n",
       " ('า', 4),\n",
       " ('เ', 4),\n",
       " ('ล', 4),\n",
       " ('เ', 4),\n",
       " ('ซ', 4),\n",
       " ('ี', 4),\n",
       " ('ย', 4),\n",
       " ('น', 4),\n",
       " ('อ', 4),\n",
       " ('ก', 4),\n",
       " ('น', 4),\n",
       " ('ั', 4),\n",
       " ('้', 4),\n",
       " ('น', 4),\n",
       " ('ก', 4),\n",
       " ('็', 4),\n",
       " ('ม', 4),\n",
       " ('ี', 4),\n",
       " ('ผ', 4),\n",
       " ('ั', 4),\n",
       " ('ด', 4),\n",
       " ('ผ', 4),\n",
       " ('ั', 4),\n",
       " ('ก', 4),\n",
       " ('น', 4),\n",
       " ('้', 4),\n",
       " ('ำ', 4),\n",
       " ('ม', 4),\n",
       " ('ั', 4),\n",
       " ('น', 4),\n",
       " ('ห', 4),\n",
       " ('อ', 4),\n",
       " ('ย', 4),\n",
       " ('ไ', 4),\n",
       " ('ก', 4),\n",
       " ('่เ', 4),\n",
       " ('บ', 4),\n",
       " ('ต', 4),\n",
       " ('ง', 4),\n",
       " (' เ', 4),\n",
       " ('ค', 4),\n",
       " ('า', 4),\n",
       " ('ห', 4),\n",
       " ('ย', 4),\n",
       " ('ก', 4),\n",
       " ('ป', 4),\n",
       " ('ู', 4),\n",
       " ('ท', 4),\n",
       " ('ะ', 4),\n",
       " ('เ', 4),\n",
       " ('ล', 4),\n",
       " ('ซ', 4),\n",
       " ('ุ', 4),\n",
       " ('ป', 4),\n",
       " ('น', 4),\n",
       " ('้', 4),\n",
       " ('ำ', 4),\n",
       " ('ใ', 4),\n",
       " ('ส', 4),\n",
       " ('ห', 4),\n",
       " ('ม', 4),\n",
       " ('้', 4),\n",
       " ('อ', 4),\n",
       " ('ไ', 4),\n",
       " ('ฟ', 4),\n",
       " ('เต้', 4),\n",
       " ('า', 4),\n",
       " ('ห', 4),\n",
       " ('ู', 4),\n",
       " ('้', 4),\n",
       " ('แ', 4),\n",
       " ('ค', 4),\n",
       " ('ร', 4),\n",
       " ('ะ', 4),\n",
       " ('ย', 4),\n",
       " ('ั', 4),\n",
       " ('ด', 4),\n",
       " ('ไ', 4),\n",
       " ('ส', 4),\n",
       " ('้', 4),\n",
       " ('ห', 4),\n",
       " ('ม', 4),\n",
       " ('้', 4),\n",
       " ('อด', 4),\n",
       " ('ิ', 4),\n",
       " ('น', 4),\n",
       " ('แ', 4),\n",
       " ('ล', 4),\n",
       " ('ะ', 4),\n",
       " ('ล', 4),\n",
       " ('ู', 4),\n",
       " ('ก', 4),\n",
       " ('ช', 4),\n",
       " ('ิ', 4),\n",
       " ('้', 4),\n",
       " ('น', 4),\n",
       " ('แ', 4),\n",
       " ('ค', 4),\n",
       " ('ร', 4),\n",
       " ('ะ', 4),\n",
       " ('', 4),\n",
       " ('อ', 4),\n",
       " ('า', 4),\n",
       " ('หา', 4),\n",
       " ('ร', 4),\n",
       " ('ท', 4),\n",
       " ('ี', 4),\n",
       " ('่', 4),\n",
       " ('เ', 4),\n",
       " ('ร', 4),\n",
       " ('า', 4),\n",
       " ('แ', 4),\n",
       " ('น', 4),\n",
       " ('ะ', 4),\n",
       " ('น', 4),\n",
       " ('ำ', 4),\n",
       " ('ค', 4),\n",
       " ('ื', 4),\n",
       " ('อ', 4),\n",
       " ('ไ', 4),\n",
       " ('ก', 4),\n",
       " ('่', 4),\n",
       " ('เบ', 4),\n",
       " ('ต', 4),\n",
       " ('ง', 4),\n",
       " (' ', 4),\n",
       " ('ค', 4),\n",
       " ('ล', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('ย', 4),\n",
       " ('ๆ', 4),\n",
       " ('ไ', 4),\n",
       " ('ก', 4),\n",
       " ('่', 4),\n",
       " ('แ', 4),\n",
       " ('ช', 4),\n",
       " ('่', 4),\n",
       " ('เ', 4),\n",
       " ('ห', 4),\n",
       " ('ล', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " (' เ', 4),\n",
       " ('ส', 4),\n",
       " ('ร', 4),\n",
       " ('ิ', 4),\n",
       " ('ฟ', 4),\n",
       " ('พ', 4),\n",
       " ('ร', 4),\n",
       " ('้', 4),\n",
       " ('อ', 4),\n",
       " ('ม', 4),\n",
       " ('ก', 4),\n",
       " ('ั', 4),\n",
       " ('บ', 4),\n",
       " ('ห', 4),\n",
       " ('อ', 4),\n",
       " ('ม', 4),\n",
       " ('เ', 4),\n",
       " ('จ', 4),\n",
       " ('ี', 4),\n",
       " ('ย', 4),\n",
       " ('ว', 4),\n",
       " ('แ', 4),\n",
       " ('ล', 4),\n",
       " ('ะ', 4),\n",
       " ('น', 4),\n",
       " ('้', 4),\n",
       " ('ำจ', 4),\n",
       " ('ิ', 4),\n",
       " ('้', 4),\n",
       " ('ม', 4),\n",
       " ('น', 4),\n",
       " ('้', 4),\n",
       " ('ำ', 4),\n",
       " ('พ', 4),\n",
       " ('ร', 4),\n",
       " ('ิ', 4),\n",
       " ('ก', 4),\n",
       " ('เ', 4),\n",
       " ('ผ', 4),\n",
       " ('า', 4),\n",
       " ('ส', 4),\n",
       " ('ู', 4),\n",
       " ('ต', 4),\n",
       " ('ร', 4),\n",
       " ('เ', 4),\n",
       " ('ด', 4),\n",
       " ('็', 4),\n",
       " ('ด', 4),\n",
       " ('ขอ', 4),\n",
       " ('ง', 4),\n",
       " ('ท', 4),\n",
       " ('า', 4),\n",
       " ('งร', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('น', 4),\n",
       " ('', 4),\n",
       " ('เ', 4),\n",
       " ('ม', 4),\n",
       " ('น', 4),\n",
       " ('ู', 4),\n",
       " ('ข', 4),\n",
       " ('้', 4),\n",
       " ('า', 4),\n",
       " ('ว', 4),\n",
       " ('ผ', 4),\n",
       " ('ั', 4),\n",
       " ('ด', 4),\n",
       " ('ห', 4),\n",
       " ('น', 4),\n",
       " ('ำ', 4),\n",
       " ('เ', 4),\n",
       " ('ล', 4),\n",
       " ('ี', 4),\n",
       " ('ย', 4),\n",
       " ('บ', 4),\n",
       " ('ก', 4),\n",
       " ('็', 4),\n",
       " ('อ', 4),\n",
       " ('ร', 4),\n",
       " ('่', 4),\n",
       " ('อ', 4),\n",
       " ('ย', 4),\n",
       " ('ค', 4),\n",
       " ('่', 4),\n",
       " ('ะ', 4),\n",
       " ('ช', 4),\n",
       " ('อ', 4),\n",
       " ('บ', 4),\n",
       " ('ม', 4),\n",
       " ('า', 4),\n",
       " ('ก', 4),\n",
       " ('ๆ', 4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeLabel(df[0][1], df[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ร้านอาหารใหญ่มากกกกกกก \\nเลี้ยวเข้ามาเจอห้องน้...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>อาหารที่นี่เป็นอาหารจีนแคะที่หากินยากในบ้านเรา...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ปอเปี๊ยะสด ทุกวันนี้รู้สึกว่าหากินยาก (ร้านที่...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>รัานคัพเค้กในเมืองไทยมีไม่มาก หลายๆคนอาจจะสงสั...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>อร่อย!!! เดินผ่านDigital gatewayทุกวัน ไม่ยักร...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ร้านข้าวต้มกระดูกหมู ปากซอยพัฒนาการ 57 เป็นอีก...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>วันนี้ได้มีโอกาสไปนั่งซดกาแฟที่ร้านวาวี แถวๆอา...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>สารภาพว่าไม่เคยคิดจะไปต่อคิวซื้อมากินเองครับ บ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>เมื่อวันก่อนไปเดินเล่น แบบชิวๆๆ ที่สยามสแควร์แ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>วันก่อนไปเดินสยาม หลังจากห่างหายไป ประมาณ 6 เด...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>พามาลองอะไรใกล้ๆ บ้านบ้างครับ .. ร้าน \"วัวหัวเ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>เพ่ิงกลับมาจากไต้หวันก็ไปลองร้านนี้ทันที ชานมไ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>เคยไปทานที่ Villa มา คนเยอะมากกกกก รอคิวนานประ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>เหมือนกับรีวิวก่อนๆค่ะ เมนูที่ห้ามพลาดก้อคือ S...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"ประจักษ์เป็ดย่าง\" \\n\\nไม่ใช่ร้านของพันตรีประจ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ร้านนี้ถ้าวิวให้หกดาวได้ผมให้วิวหกดาว..\\n\\nร้า...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ก้ำกึ่งระหว่าง 4 ดาวกับ 5 ดาว แต่ถ้าเทียบกับร้...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>เป็นร้านที่มีเครื่องดื่มให้เลือกมากมาย และรสชา...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ร้านคุณภาพอีกร้านนึงครับ ปกติกินที่สาขาสยามรู้...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ก๋วยเตี๋ยวลูกชิ้นปลาย่านคลองเตยร้านนี้เปิดมาเป...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ร้านอาหารญี่ปุ่นร้านนี้ ใจจริงไม่อยากแนะนำเลยค...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ร้านชีสเค้กต้นตำรับจากนิวยอร์ก\\nร้านอยู่ที่CDC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ระหว่างทางไปเขาค้อ ผมได้คำแนะนำจากเด็กปั๊มให้ม...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ใครที่เดินทางไปเที่ยวชะอำหรือหัวหิน ก็ต้องหาอา...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>เดือนแรกที่เค้าต่อคิวกัน 2 - 3 ชั่วโมง เราก็ว่...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>หลังจากที่โดนยั่วโดยหลายๆ เว็บ หลายๆ ทวีต วันน...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>เข้าวังไปจิบกาแฟกันนะครับ บอกได้เลยว่า มาร้านน...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>กินจนติดมาก เป็นร้านที่กินแล้ว \"สนุกลิ้น\" มากจ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>เพิ่งจะเปิดได้ไม่กี่ปีแต่ต้องยอมรับว่าเค้าประส...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ร้านไอส์เบิร์กอยู่ที่นครปฐม ทั้งร้านขายไอศกรีม...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39970</th>\n",
       "      <td>เป็นร้านเล็กๆ ของโรงแรมคอนราดตั้งอยุ่ชั้น 2 ขอ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39971</th>\n",
       "      <td>รู้สึกว้าววกับเมนูนี้มากเลยยค่าปป ผมรู้สึกมันเ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39972</th>\n",
       "      <td>???? Hongbao Dimsum House~ rest area ทางด่วนปร...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39973</th>\n",
       "      <td>พนักงานบริการดี อาหารคุ้มกับราคาค่ะ ร้านใหญ่ ภ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39974</th>\n",
       "      <td>ร้านหมูกระทะที่มีทุกอย่างครบคลุมไว้ละปิ้งย่าง ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39975</th>\n",
       "      <td>ร้านเทมปุระ ที่ได้รับการแนะนำจาก Tripadvisor เ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39976</th>\n",
       "      <td>กินเส้น กรือกินเนื้อ หรือกินหยัง เลือกเอา เลือ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39977</th>\n",
       "      <td>กาแฟมิตรสัมพันธ์ – สิ่งที่เราชอบเกี่ยวกับร้านก...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39978</th>\n",
       "      <td>ชื่อร้านก็บอกแล้วว่าสารพัดเส้น ก็ต้องจัดเส้น เ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39979</th>\n",
       "      <td>ร้านอาหารที่อยู่โซนหน้าห้างเซ็นทรัลอีสต์วิลล์ ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39980</th>\n",
       "      <td>มื้อกลางวันวันนี้ เราแวะมาทานที่  Jewelry Trad...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>ขนมจีนน้ำยาปู หาร้านทำอร่อยยากอยู่นะ เคยกินบาง...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39982</th>\n",
       "      <td>บางครั้งหิวตอนดึกๆ หรือนัดเพื่อนฝูงตอนกลางคืน ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39983</th>\n",
       "      <td>Osha Cafe' ตั้งอยู่บริเวณโกดัง10 ของโครงการAsi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39984</th>\n",
       "      <td>ฝากท้องฝากไส้กันไป ออกมานอกพื้นที่ ทานร้านริมท...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>ร้านกาแฟ ในเชียงใหม่ มีมากมายหลายร้าน ยิ่งกว่า...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>โดนัทเจ้าดังที่สร้างตำนานคิวย๊าวยาวววว จริงๆกิ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>เวลามาสีลมแล้วอย่กนั่งชิล หรือทำงานไปด้วยก็จะเ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>ร้านเจ้าประจำเวลานึกถึงกาแฟอีกร้าน แต่ถ้าเป็นช...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>ร้านข้าวมันไก่ในซอยวัดหนองขาม มาแวะซื้อใส่กล่อ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39990</th>\n",
       "      <td>ร้านอยู่กลางเมกะบางนา ตรงประชาสัมพันธ์ ใต้บันไ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39991</th>\n",
       "      <td>เป็นร้านนั่งชิวขึ้นชื่อของโซนนี้ที่ต้องมาลองให...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39992</th>\n",
       "      <td>ร้านที่ชื่อแปลก ตกแต่งสไตล์loft ได้อย่างลงตัว ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39993</th>\n",
       "      <td>นั่งกิน Bar B Q กันอยู่ มองไปทาง food court เห...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>\"อร่อย ขนมจีบ ซาลาเปา\" ขนมจีบลูกใหญ่ กับซาลาเป...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>รู้จักร้านนี้จากวงใน ร้านอยู่ในอาคารพาณิชย์ตรง...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>ร้านซูชิอาหารญี่ปุ่น อยู่ตรงสะพานลอย เกษตรประต...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>\"Cantina Wine Bar &amp; Italian Kitchen\" ร้านเล็กๆ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>ร้านเค้กน่ารักๆ ตรงชั้นล่างของห้างเซ็นทรัลลาดพ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>วันนี้มากินกันไกลถึงแม่สอดจังหวัดตากติดกับชายแ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  1\n",
       "0      ร้านอาหารใหญ่มากกกกกกก \\nเลี้ยวเข้ามาเจอห้องน้...  3\n",
       "1      อาหารที่นี่เป็นอาหารจีนแคะที่หากินยากในบ้านเรา...  4\n",
       "2      ปอเปี๊ยะสด ทุกวันนี้รู้สึกว่าหากินยาก (ร้านที่...  3\n",
       "3      รัานคัพเค้กในเมืองไทยมีไม่มาก หลายๆคนอาจจะสงสั...  5\n",
       "4      อร่อย!!! เดินผ่านDigital gatewayทุกวัน ไม่ยักร...  5\n",
       "5      ร้านข้าวต้มกระดูกหมู ปากซอยพัฒนาการ 57 เป็นอีก...  4\n",
       "6      วันนี้ได้มีโอกาสไปนั่งซดกาแฟที่ร้านวาวี แถวๆอา...  4\n",
       "7      สารภาพว่าไม่เคยคิดจะไปต่อคิวซื้อมากินเองครับ บ...  3\n",
       "8      เมื่อวันก่อนไปเดินเล่น แบบชิวๆๆ ที่สยามสแควร์แ...  5\n",
       "9      วันก่อนไปเดินสยาม หลังจากห่างหายไป ประมาณ 6 เด...  5\n",
       "10     พามาลองอะไรใกล้ๆ บ้านบ้างครับ .. ร้าน \"วัวหัวเ...  4\n",
       "11     เพ่ิงกลับมาจากไต้หวันก็ไปลองร้านนี้ทันที ชานมไ...  4\n",
       "12     เคยไปทานที่ Villa มา คนเยอะมากกกกก รอคิวนานประ...  4\n",
       "13     เหมือนกับรีวิวก่อนๆค่ะ เมนูที่ห้ามพลาดก้อคือ S...  4\n",
       "14     \"ประจักษ์เป็ดย่าง\" \\n\\nไม่ใช่ร้านของพันตรีประจ...  4\n",
       "15     ร้านนี้ถ้าวิวให้หกดาวได้ผมให้วิวหกดาว..\\n\\nร้า...  4\n",
       "16     ก้ำกึ่งระหว่าง 4 ดาวกับ 5 ดาว แต่ถ้าเทียบกับร้...  5\n",
       "17     เป็นร้านที่มีเครื่องดื่มให้เลือกมากมาย และรสชา...  5\n",
       "18     ร้านคุณภาพอีกร้านนึงครับ ปกติกินที่สาขาสยามรู้...  4\n",
       "19     ก๋วยเตี๋ยวลูกชิ้นปลาย่านคลองเตยร้านนี้เปิดมาเป...  5\n",
       "20     ร้านอาหารญี่ปุ่นร้านนี้ ใจจริงไม่อยากแนะนำเลยค...  5\n",
       "21     ร้านชีสเค้กต้นตำรับจากนิวยอร์ก\\nร้านอยู่ที่CDC...  4\n",
       "22     ระหว่างทางไปเขาค้อ ผมได้คำแนะนำจากเด็กปั๊มให้ม...  3\n",
       "23     ใครที่เดินทางไปเที่ยวชะอำหรือหัวหิน ก็ต้องหาอา...  4\n",
       "24     เดือนแรกที่เค้าต่อคิวกัน 2 - 3 ชั่วโมง เราก็ว่...  5\n",
       "25     หลังจากที่โดนยั่วโดยหลายๆ เว็บ หลายๆ ทวีต วันน...  5\n",
       "26     เข้าวังไปจิบกาแฟกันนะครับ บอกได้เลยว่า มาร้านน...  4\n",
       "27     กินจนติดมาก เป็นร้านที่กินแล้ว \"สนุกลิ้น\" มากจ...  4\n",
       "28     เพิ่งจะเปิดได้ไม่กี่ปีแต่ต้องยอมรับว่าเค้าประส...  5\n",
       "29     ร้านไอส์เบิร์กอยู่ที่นครปฐม ทั้งร้านขายไอศกรีม...  4\n",
       "...                                                  ... ..\n",
       "39970  เป็นร้านเล็กๆ ของโรงแรมคอนราดตั้งอยุ่ชั้น 2 ขอ...  4\n",
       "39971  รู้สึกว้าววกับเมนูนี้มากเลยยค่าปป ผมรู้สึกมันเ...  5\n",
       "39972  ???? Hongbao Dimsum House~ rest area ทางด่วนปร...  4\n",
       "39973  พนักงานบริการดี อาหารคุ้มกับราคาค่ะ ร้านใหญ่ ภ...  4\n",
       "39974  ร้านหมูกระทะที่มีทุกอย่างครบคลุมไว้ละปิ้งย่าง ...  3\n",
       "39975  ร้านเทมปุระ ที่ได้รับการแนะนำจาก Tripadvisor เ...  4\n",
       "39976  กินเส้น กรือกินเนื้อ หรือกินหยัง เลือกเอา เลือ...  4\n",
       "39977  กาแฟมิตรสัมพันธ์ – สิ่งที่เราชอบเกี่ยวกับร้านก...  4\n",
       "39978  ชื่อร้านก็บอกแล้วว่าสารพัดเส้น ก็ต้องจัดเส้น เ...  3\n",
       "39979  ร้านอาหารที่อยู่โซนหน้าห้างเซ็นทรัลอีสต์วิลล์ ...  4\n",
       "39980  มื้อกลางวันวันนี้ เราแวะมาทานที่  Jewelry Trad...  3\n",
       "39981  ขนมจีนน้ำยาปู หาร้านทำอร่อยยากอยู่นะ เคยกินบาง...  4\n",
       "39982  บางครั้งหิวตอนดึกๆ หรือนัดเพื่อนฝูงตอนกลางคืน ...  4\n",
       "39983  Osha Cafe' ตั้งอยู่บริเวณโกดัง10 ของโครงการAsi...  4\n",
       "39984  ฝากท้องฝากไส้กันไป ออกมานอกพื้นที่ ทานร้านริมท...  4\n",
       "39985  ร้านกาแฟ ในเชียงใหม่ มีมากมายหลายร้าน ยิ่งกว่า...  4\n",
       "39986  โดนัทเจ้าดังที่สร้างตำนานคิวย๊าวยาวววว จริงๆกิ...  4\n",
       "39987  เวลามาสีลมแล้วอย่กนั่งชิล หรือทำงานไปด้วยก็จะเ...  3\n",
       "39988  ร้านเจ้าประจำเวลานึกถึงกาแฟอีกร้าน แต่ถ้าเป็นช...  4\n",
       "39989  ร้านข้าวมันไก่ในซอยวัดหนองขาม มาแวะซื้อใส่กล่อ...  3\n",
       "39990  ร้านอยู่กลางเมกะบางนา ตรงประชาสัมพันธ์ ใต้บันไ...  3\n",
       "39991  เป็นร้านนั่งชิวขึ้นชื่อของโซนนี้ที่ต้องมาลองให...  4\n",
       "39992  ร้านที่ชื่อแปลก ตกแต่งสไตล์loft ได้อย่างลงตัว ...  4\n",
       "39993  นั่งกิน Bar B Q กันอยู่ มองไปทาง food court เห...  3\n",
       "39994  \"อร่อย ขนมจีบ ซาลาเปา\" ขนมจีบลูกใหญ่ กับซาลาเป...  4\n",
       "39995  รู้จักร้านนี้จากวงใน ร้านอยู่ในอาคารพาณิชย์ตรง...  4\n",
       "39996  ร้านซูชิอาหารญี่ปุ่น อยู่ตรงสะพานลอย เกษตรประต...  4\n",
       "39997  \"Cantina Wine Bar & Italian Kitchen\" ร้านเล็กๆ...  5\n",
       "39998  ร้านเค้กน่ารักๆ ตรงชั้นล่างของห้างเซ็นทรัลลาดพ...  3\n",
       "39999  วันนี้มากินกันไกลถึงแม่สอดจังหวัดตากติดกับชายแ...  3\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = df[:][:40000]\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(len(demo)):\n",
    "    train.append((demo[0][i], demo[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_htmlTags(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext\n",
    "    \n",
    "def isValidWord(text):\n",
    "    dic = {text[0]:1}\n",
    "    for c in text[1:]:\n",
    "        if c not in dic:\n",
    "            return True\n",
    "        else:\n",
    "            dic[c] += 1\n",
    "    if dic[text[0]] > 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def tokenize(review):\n",
    "    \n",
    "#     tags = tltk.nlp.pos_tag(review.replace(\"\\n\", \"\"))\n",
    "#     noSpace = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, cutKumKrub(review)))\n",
    "#     cleaned = list(filter(lambda x: len(x.replace(\" \\n\", \"\")) > 0 and len(x.replace(\")\", \"\")) > 0, noSpace)) \n",
    "#     for i in range(len(cleaned)):\n",
    "#         cleaned[i] = cleaned[i].replace(\"\\n\", \"\")\n",
    "#         cleaned[i] = cleaned[i].replace(\"(\", \"\")\n",
    "#         cleaned[i] = cleaned[i].replace(\")\", \"\")\n",
    "#     finalWord = list(filter(lambda x: len(x.replace(\" \", \"\")) > 0, cleaned))\n",
    "\n",
    "    # Filter parts of speech of text\n",
    "    tags = tltk.nlp.pos_tag(remove_htmlTags(review.replace(\"\\n\", \"\")))\n",
    "    finalWord = []\n",
    "    filteredTags = {'NOUN', 'VERB', 'ADJ','ADV', 'AUX', 'PART'}\n",
    "    for sentence in tags:\n",
    "        for word, tag in sentence:\n",
    "            if tag in filteredTags:\n",
    "                if len(word) > 1 and isValidWord(word):\n",
    "                    finalWord.append(remove_htmlTags(word))\n",
    "    return finalWord\n",
    "\n",
    "# tokenize(train[0][0])\n",
    "# train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "# vocabulary = set(chain(*[tokenize(i[0].lower()) for i in train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vocabulary\n",
    "tokenize(train[999][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/40000\n",
      "2/40000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a46f7d228e8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-e8b6dcdc9a8d>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Filter parts of speech of text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_htmlTags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mfinalWord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mfilteredTags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'NOUN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VERB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ADJ'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ADV'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AUX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PART'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tltk/nlp.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(Input, Option)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_segment_mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_segment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<s/>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mtag_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tltk/nlp.py\u001b[0m in \u001b[0;36mword_segment\u001b[1;34m(Input)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msylseg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordseg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mWordSep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tltk/nlp.py\u001b[0m in \u001b[0;36msylseg\u001b[1;34m(Input)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEndOfInput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mInx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mmatchObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mInx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmatchObj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m                 \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatchObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/re.py\u001b[0m in \u001b[0;36mmatch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \"\"\"Try to apply the pattern at the start of the string, returning\n\u001b[0;32m    162\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfullmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m     \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[1;31m# print(code)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/sre_compile.py\u001b[0m in \u001b[0;36m_code\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[1;31m# compile the pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m     \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[0mcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/sre_compile.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(code, pattern, flags)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLITERAL_CODES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mSRE_FLAG_IGNORECASE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                 \u001b[0mlo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfixes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfixes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "corpus = []\n",
    "for i in range(len(train)):\n",
    "    print(str(i+1) + \"/\" + str(len(train)))\n",
    "    corpus.append(tokenize(train[i][0]))\n",
    "\n",
    "corpus\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# pickle_out = open(\"corpus.pickle\",\"wb\")\n",
    "# pickle.dump(corpus, pickle_out)\n",
    "# pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-f7c874dad355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpickle_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"corpus_test.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"corpus3.pickle\",\"rb\")\n",
    "corpus1 = pickle.load(pickle_in)\n",
    "print(len(corpus1))\n",
    "\n",
    "pickle_in = open(\"corpus_test.pickle\",\"rb\")\n",
    "test_set = pickle.load(pickle_in)\n",
    "len(test_set)\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4124"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"corpus2.pickle\",\"rb\")\n",
    "corpus2 = pickle.load(pickle_in)\n",
    "len(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus\n",
    "# corpus = corpus1 + corpus2\n",
    "\n",
    "newcor = corpus1\n",
    "test = test_set\n",
    "# tltk.nlp.pos_tag(train[0][0])\n",
    "len(newcor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x, binary = True)\n",
    "tfidf_matrix = tfidf.fit_transform(newcor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40000x171636 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3587066 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# idf = tfidf.idf_\n",
    "# print (tfidf.get_feature_names(), idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corpus = [\n",
    "#     tokenize(df[0][0]),\n",
    "#     tokenize(df[0][1]),\n",
    "#     tokenize(df[0][2])\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# pca = PCA(n_components = 300)\n",
    "\n",
    "# x_train = pca.fit_transform(x_train)\n",
    "svd = TruncatedSVD(n_components=300, n_iter=10, random_state=42)\n",
    "x_train = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for i in range(40000):\n",
    "    y_train.append(train[i][1])\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "# tfidf_matrix.toarray().shape\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 300)\n",
      "[[ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "tfidf_matrix = tfidf.transform(newcor[36000:])\n",
    "# print(tfidf_matrix)\n",
    "x_test = svd.transform(tfidf_matrix)\n",
    "\n",
    "tfidf_matrix = tfidf.transform(test)\n",
    "x_test_r = svd.transform(tfidf_matrix)\n",
    "y_test = []\n",
    "\n",
    "\n",
    "for i in range(36000,40000):\n",
    "    y_test.append(train[i][1])\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "# predictions = classifier.predict(x_test)\n",
    "print(x_train.shape)\n",
    "y_train.reshape(40000, 1)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_train = y_train[:, 1:]\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 5000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-2a80faf52aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# x_train.mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    691\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 5000]"
     ]
    }
   ],
   "source": [
    "# x_train.mean()\n",
    "# predictions\n",
    "f1_score(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18891432308698497"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = linearClassifier.predict(x_test)\n",
    "predictions\n",
    "f1_score(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "40000/40000 [==============================] - 72s - loss: 1.2214 - f1: nan    \n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 73s - loss: 1.1722 - f1: nan    \n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 73s - loss: 1.1361 - f1: 0.3093    \n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 72s - loss: 1.1174 - f1: 0.3371    \n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 73s - loss: 1.0971 - f1: 0.3590    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/__main__.py:77: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=128, activation=\"relu\", input_shape=(300, 1), padding=\"same\", kernel_size=3)`\n",
      "/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/__main__.py:81: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(padding=\"same\", filters=128, activation=\"relu\", kernel_size=3)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5c1532b70>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components = 300)\n",
    "# x_train = tfidf_matrix.toarray()\n",
    "# x_train = pca.fit_transform(x_train)\n",
    "# y_train = []\n",
    "\n",
    "# for i in range(3500):\n",
    "#     y_train.append(train[i][1])\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "rate = 0.3\n",
    "\n",
    "# def get_feedforward_nn():\n",
    "#   input1 = Input(shape=(300,))\n",
    "#   x = Dense(300, activation='relu')(input1)\n",
    "#   x = Dropout(rate)(x)\n",
    "#   x = Dense(128, activation='relu')(x)\n",
    "#   x = Dropout(rate)(x)  \n",
    "#   out = Dense(1, activation='relu')(x)\n",
    "\n",
    "#   model = Model(inputs=input1, outputs=out)\n",
    "#   model.compile(optimizer=Adam(),\n",
    "#                 loss='mean_squared_error',\n",
    "#                 metrics=[f1])\n",
    "#   return model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "#CNN\n",
    "classifier.add(Conv1D(nb_filter = 128, filter_length = 3, input_shape = (300,1), padding = \"same\", activation = 'relu'))\n",
    "classifier.add(MaxPooling1D())\n",
    "# classifier.add(Dropout(0.3))\n",
    "\n",
    "classifier.add(Conv1D(nb_filter = 128, filter_length = 3, padding = \"same\", activation = 'relu'))\n",
    "classifier.add(MaxPooling1D())\n",
    "# classifier.add(Dropout(0.2))\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "# classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dropout(0.3))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "# classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# classifier.add(Dropout(0.3))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [f1])\n",
    "\n",
    "# for c in y_train:\n",
    "#     if c not in {1, 2, 3, 4, 5}:\n",
    "#         print(y)\n",
    "classifier.fit(np.expand_dims(x_train, axis = 2), y_train, batch_size = 256, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = classifier.predict(np.expand_dims(x_test, axis = 2))\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 2, 4, 4, 3, 4, 4, 4, 4, 4, 3, 5, 4, 4, 2, 3, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 5, 4, 4, 4, 5, 3, 4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 3, 4, 5, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 2, 4, 5, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 5, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 5, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 5, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 5, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 5, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 5, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3, 5, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 4, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 4, 2, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 3, 5, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 5, 4, 4, 3, 3, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 5, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 5, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 2, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 2, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 3, 3, 3, 4, 5, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 5, 4, 4, 3, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 5, 3, 3, 4, 4, 4, 5, 4, 4, 3, 4, 4, 5, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 2, 3, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 2, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 3, 4, 4, 4, 4, 5, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 1, 3, 4, 4, 3, 4, 4, 4, 4, 4, 5, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 3, 4, 5, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 5, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 5, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 4, 4, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 5, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 5, 4, 4, 4, 3, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 3, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 2, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 2, 4, 4, 4, 4, 4, 3, 5, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 3, 3, 4, 4, 3, 4, 3, 3, 4, 4, 4, 5, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 3, 3, 4, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 5, 4, 3, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 5, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 5, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 5, 4, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 3, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 5, 4, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 3, 3, 2, 5, 3, 4, 4, 2, 4, 2, 4, 3, 4, 4, 4, 5, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 3, 4, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 5, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 5, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 3, 4, 3, 4, 3, 4, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 5, 3, 4, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 5, 4, 4, 3, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 5, 4, 3, 4, 5, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 5, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 2, 4, 4, 4, 4, 5, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 3, 3, 3, 4, 3, 4, 4, 3, 5, 3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 3, 4, 2, 4, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 2, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 5, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 2, 4, 5, 4, 5, 4, 4, 4, 4, 4, 3, 4, 2, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52649999999999997"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(len(res)):\n",
    "    predictions.append(np.argmax(res[i]) + 1)\n",
    "print(predictions)\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "f1_score(y_test,predictions, average='micro')\n",
    "# print(len(predictions))\n",
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewID  rating\n",
       "0         1       4\n",
       "1         2       3\n",
       "2         3       3\n",
       "3         4       4\n",
       "4         5       4\n",
       "5         6       5\n",
       "6         7       4\n",
       "7         8       3\n",
       "8         9       4\n",
       "9        10       4"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.DataFrame({\"reviewID\": np.arange(1,len(res)+1),\"rating\": predictions}, columns=[\"reviewID\", \"rating\"])\n",
    "df_res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_res.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 300)\n",
      "train with 50 epochs and 64 batch size\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have shape (None, 1) but got array with shape (3500, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-a185a4790c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   model_feedforward_nn.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n\u001b[1;32m     34\u001b[0m                            \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list_feedforward_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                            validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1556\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1411\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1414\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1415\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have shape (None, 1) but got array with shape (3500, 5)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# This is called to clear the original model session in order to use TensorBoard\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# Path to save model parameters\n",
    "weight_path_feedforward_nn='~/workspace/model/model_weight_feedforward_nn2.h5'\n",
    "\n",
    "# Training callbacks list. TensorBoard() write logs for tensorboard GUI. \n",
    "# ModelCheckpoint() writes the resulting model.\n",
    "# Note that writing to disk takes time (longer than model training time). \n",
    "# For other sections, you might not writing any files to disk \n",
    "# or write only the graph for TensorBoard.\n",
    "callbacks_list_feedforward_nn = [\n",
    "        TensorBoard(log_dir='~/workspace/model/Graph/ff2', histogram_freq=1, write_graph=True, write_grads=True),\n",
    "        ModelCheckpoint(\n",
    "            weight_path_feedforward_nn,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        )\n",
    "  ]\n",
    "\n",
    "print(x_train.shape)\n",
    "verbose = 1\n",
    "model_feedforward_nn = get_feedforward_nn()\n",
    "train_params = [(50, 64)]\n",
    "for (epochs, batch_size) in train_params:\n",
    "  print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
    "  model_feedforward_nn.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
    "                           callbacks=callbacks_list_feedforward_nn,\n",
    "                           validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.layers import Dropout\n",
    "\n",
    "# def get_nn_with_dropout():\n",
    "    \n",
    "#     rate = 0.1\n",
    "    \n",
    "#     input1 = Input(shape=(21,))\n",
    "#     x = Dense(100, activation='relu')(input1)\n",
    "#     x = Dropout(rate)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(rate)(x)\n",
    "#     x = Dense(100, activation='relu')(x)\n",
    "#     x = Dropout(rate)(x)\n",
    "#     out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#     model = Model(inputs=input1, outputs=out)\n",
    "#     model.compile(optimizer=Adam(),\n",
    "#                 loss='binary_crossentropy',\n",
    "#                 metrics=['acc'])\n",
    "#     return model\n",
    "\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "\n",
    "################################################################################\n",
    "# Write a function to evaluate your model. Your function must make prediction  #\n",
    "# using the input model and return f-score, precision, and recall of the model.#\n",
    "# You can make predictions by calling model.predict().                         #\n",
    "################################################################################\n",
    "def evaluate(x_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Evaluate model on the splitted 10 percent testing set.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "#     #map probability to class\n",
    "#     prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "#     y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
    "#     for i in range(len(y_pred)):\n",
    "#         if y_pred[i] - int(y_pred[i]) >= 0.5:\n",
    "#             y_pred[i] = int(y_pred[i]) + 1\n",
    "#         else:\n",
    "#             y_pred[i] = int(y_pred[i])\n",
    "    print(y_pred.T[0])\n",
    "    print(y_test)\n",
    "    f1score = f1_score(y_test,y_pred.T[0], average='macro')\n",
    "    precision = precision_score(y_test,y_pred,average='macro')\n",
    "    recall = recall_score(y_test,y_pred,average='macro')\n",
    "    return f1score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv1d_15_input to have 3 dimensions, but got array with shape (1000, 300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-6806c99f29df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(x_test.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# y_pred = classifier.predict(x_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-9c3d36a11115>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(x_test, y_test, model)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mEvaluate\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msplitted\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#     #map probability to class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1729\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekkalakleelasornchai/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv1d_15_input to have 3 dimensions, but got array with shape (1000, 300)"
     ]
    }
   ],
   "source": [
    "# print(x_test.shape)\n",
    "# y_pred = classifier.predict(x_test)\n",
    "evaluate(x_test, y_test, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
